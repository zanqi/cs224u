{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9804d50-4eb0-4f1d-a20d-d6c3dbb0fd65",
   "metadata": {},
   "source": [
    "# Homework and bakeoff: Compositional generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c401fbca-fc3d-4e35-bb84-15b1ce9b974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts and Zhengxuan Wu\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117fc266-35fd-4321-beb2-8805073ebcdf",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_recogs.ipynb)\n",
    "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/cgpotts/cs224u/blob/master/hw_recogs.ipynb)\n",
    "\n",
    "If Colab is opened with this badge, please save a copy to drive (from the File menu) before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2111f33-11d7-455d-a1cb-5f0c828559dd",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c392958-5e6c-4a57-88b6-dc2880928692",
   "metadata": {},
   "source": [
    "This assignment is about _compositional generalization_. We are going to assess the degree to which our apparently very good models have learned to process and interpret language _systematically_. To do this, we are going to ask them to interpret novel combinations of familiar words and phrases. For humans, these tasks are very easy. For our models, the situation seems to be quite different.\n",
    "\n",
    "The basis for the assignment is the ReCOGS dataset of [Wu, Manning, and Potts 2023](https://arxiv.org/abs/2303.13716). ReCOGS modifies the COGS dataset of [Kim and Linzen 2020](https://aclanthology.org/2020.emnlp-main.731) in a number of ways, with the goal of more directly assessing the interpretive abilities of models.\n",
    "\n",
    "The assignment questions are fairly diverse. Question 1 asks you to conduct a specific analysis of the ReCOGS dataset, and Question 2 follows this up with a corresponding analysis of the errors made by a top-performing ReCOGS model. For Question 3, you try some in-context learning with DSP. And then we open things up as usual: you can do anything you want for your original system, and you enter that system's predictions into a bakeoff.\n",
    "\n",
    "There is only one rule that we need to enforce throughout this work:\n",
    "\n",
    "__You cannot train your system on any examples from `dataset[\"gen\"]`, nor can the output representations from those examples be included in any prompts used for in-context learning.__\n",
    "\n",
    "The nature of your original system is otherwise unconstrained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62709719-bfb2-45fe-908f-8ea72caf2470",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07497e3f-50cc-4224-b04b-23b7ed5577c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import datasets\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/cgpotts/cs224u/\n",
    "    !pip install -r cs224u/requirements.txt\n",
    "    import sys\n",
    "    sys.path.append(\"cs224u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b7d665d-000e-4bae-83a8-1f7c78879df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from compgen import recogs_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panda column width to dynamic\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da265b5-a622-4f75-b0df-60cc53f7273e",
   "metadata": {},
   "source": [
    "The default location of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23eaea62-edd6-4f41-add5-353b186782ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIRNAME = os.path.join(\"data\", \"recogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11f934-f2c3-4bc3-8c5f-d3dbbd450eb1",
   "metadata": {},
   "source": [
    "The following code should grab the dataset for you; if it fails for any reason, you can manually download it from [this link](https://web.stanford.edu/class/cs224u/data/recogs.tgz) and then put it in `SRC_DIRNAME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b902be49-6380-46ae-a353-a634b1cab256",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SRC_DIRNAME):\n",
    "    !mkdir -p data\n",
    "    !wget https://web.stanford.edu/class/cs224u/data/recogs.tgz -P data\n",
    "    !tar xvf data/recogs.tgz -C data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da14956-1813-4372-b747-d7a2dbd10bc1",
   "metadata": {},
   "source": [
    "## Load the COGS and ReCOGS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49118e3a-a4fc-4a6a-9d88-c0f8371a390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(filename):\n",
    "    return pd.read_csv(\n",
    "        filename,\n",
    "        delimiter=\"\\t\",\n",
    "        names=['input', 'output', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5fda2c30-a788-4a62-806c-f7318797474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "for splitname in (\"train\", \"dev\", \"gen\", \"test\"):\n",
    "    dataset[splitname] = load_split(f\"{SRC_DIRNAME}/{splitname}.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a50d3-6f83-4c66-bea5-548ccf25ba7a",
   "metadata": {},
   "source": [
    "Here's a look at the dataset. Fundamentally, the task is to map simple English sentences to logical forms. For ReCOGS, you need only predict these forms up to semantic equivalence, which means that we abstract away from the order of the conjuncts and the names of specific variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6900c28-1949-419b-a8e4-9d534f973dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rose was helped by a dog .</td>\n",
       "      <td>rose ( 1 ) ; dog ( 6 ) ; help ( 3 ) AND theme ( 3 , 1 ) AND agent ( 3 , 6 )</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sailor dusted a boy .</td>\n",
       "      <td>* sailor ( 1 ) ; boy ( 4 ) ; dust ( 2 ) AND agent ( 2 , 1 ) AND theme ( 2 , 4 )</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          input  \\\n",
       "0  A rose was helped by a dog .   \n",
       "1     The sailor dusted a boy .   \n",
       "\n",
       "                                                                            output  \\\n",
       "0      rose ( 1 ) ; dog ( 6 ) ; help ( 3 ) AND theme ( 3 , 1 ) AND agent ( 3 , 6 )   \n",
       "1  * sailor ( 1 ) ; boy ( 4 ) ; dust ( 2 ) AND agent ( 2 , 1 ) AND theme ( 2 , 4 )   \n",
       "\n",
       "          category  \n",
       "0  in_distribution  \n",
       "1  in_distribution  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(dataset['train']) == 135547, \"V2\"\n",
    "# assert len(dataset['train']) == 135546, \"V1\"\n",
    "assert len(dataset['train']) == 27227, \"Positional Index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03961b86-b824-4c5f-8e54-8258b71a6466",
   "metadata": {},
   "source": [
    "The `dataset['gen']` section is divided up into different 21 categories. A category name `X_to_Y` or `only_seen_as_X_as_Y`  means that specific phrases were seen only as `X` in training and will encounter those phrases as `Y` at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9eb7e84b-5304-4d4c-a0a5-919ff79a7730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['active_to_passive',\n",
       " 'cp_recursion',\n",
       " 'do_dative_to_pp_dative',\n",
       " 'obj_omitted_transitive_to_transitive',\n",
       " 'obj_pp_to_subj_pp',\n",
       " 'obj_to_subj_common',\n",
       " 'obj_to_subj_proper',\n",
       " 'only_seen_as_transitive_subj_as_unacc_subj',\n",
       " 'only_seen_as_unacc_subj_as_obj_omitted_transitive_subj',\n",
       " 'only_seen_as_unacc_subj_as_unerg_subj',\n",
       " 'passive_to_active',\n",
       " 'pp_dative_to_do_dative',\n",
       " 'pp_recursion',\n",
       " 'prim_to_inf_arg',\n",
       " 'prim_to_obj_common',\n",
       " 'prim_to_obj_proper',\n",
       " 'prim_to_subj_common',\n",
       " 'prim_to_subj_proper',\n",
       " 'subj_to_obj_common',\n",
       " 'subj_to_obj_proper',\n",
       " 'unacc_to_transitive']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dataset['gen'].category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264a754-0903-40bf-8012-9abd9d7a41dc",
   "metadata": {},
   "source": [
    "## Question 1: Proper names and their semantic roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aaeec-4de8-4d7f-a90f-334117b4ea04",
   "metadata": {},
   "source": [
    "A number of the COGS/ReCOGS generalization categories assess models on their ability to handle proper names appearing in novel positions at test time. For example, in the `obj_to_subj_proper` category, models encounter proper names that appeared in the train set only in grammatical object position (e.g., _see Sandy_), and then they are asked to make predictions about cases where those names are grammatical subjects (_Sandy left_). These changes have systematic effects on the grammatical roles that the meanings of these names play semantically. In particular, subjects are likely to play `agent` roles and objects are likely to play `theme` roles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb7cb6-5e43-4697-89eb-c16c592209b1",
   "metadata": {},
   "source": [
    "### Task 1: Pattern-based analysis function [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d0f81-cd75-4895-9414-1ada5c9c9f28",
   "metadata": {},
   "source": [
    "Write a function that scans ReCOGS logical forms to determine what role proper names play. The following are the core steps:\n",
    "\n",
    "1. Identify proper names. All and only proper names begin with capital letters in these LFs, and proper names consist only of ascii letters. The format is, informally, `Name ( d+ )`, as in `Sandy ( 47 )`.\n",
    "\n",
    "2. Identify role expressions. The pattern is always `role ( d+ , d+ )`, as in `agent ( 1 , 47 )`. Here, the first variable is for the associated event, and the second is the role argument. The possible roles are `agent`, `theme`, and `recipient`. (The dataset includes other roles, but these involve events, not people.)\n",
    "\n",
    "3. Determine which of the above are linked in the sense that the variable names are the same. A given name can link to multiple role expressions (or none at all), and LFs can contain multiple names and multiple role expressions.\n",
    "\n",
    "To do the above, you just need to complete the function `get_propername_role`. The test should clear up any ambiguity and help you iterate to a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f3a19570-3a3c-4843-a9de-f48f2b746dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import DefaultDict\n",
    "\n",
    "def get_propername_role(s):\n",
    "    \"\"\"Extract from `s` all the pairs `(name, role)` determined by\n",
    "    binding relationships. There can be multiple tokens of the same\n",
    "    name with different variables, as in \"Kim ( 1 )\" and \"Kim ( 47 )\",\n",
    "    and there can be instances in which a single name with variable\n",
    "    like \"Kim ( 1 )\" binds into multiple role expressions like\n",
    "    \"agent ( 4 , 1 )\" and \"theme ( 6 , 1 )\". Your function should\n",
    "    cover all these cases.\n",
    "\n",
    "    We've suggested a particular program design to get you started,\n",
    "    but you are free to do something different and perhaps cleverer\n",
    "    if you wish!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    set of tuples `(name, role)` where `name` and `role` are str\n",
    "    \"\"\"\n",
    "    # Step 1: Define a regex for \"name ( var )\" expressions:\n",
    "    ##### YOUR CODE HERE\n",
    "    name_re = r\"([A-Z]\\w+)\\s+\\(\\s+(\\d+)\\s+\\)\"\n",
    "\n",
    "\n",
    "    # Step 2: Define a regex for \"role ( var , var )\" expressions:\n",
    "    ##### YOUR CODE HERE\n",
    "    role_re = r\"(\\w+)\\s+\\(\\s+(\\d+)\\s*,\\s+(\\d+)\\s+\\)\"\n",
    "\n",
    "\n",
    "    # Step 3: Use `findall` with both of your regexs:\n",
    "    ##### YOUR CODE HERE\n",
    "    matches = re.findall(name_re, s) + re.findall(role_re, s)\n",
    "\n",
    "\n",
    "\n",
    "    # Step 4: Loop overall combinations of matches from your regexs\n",
    "    # to build `data` as a set of pairs `(name, role)`:\n",
    "    data = set()\n",
    "    ##### YOUR CODE HERE\n",
    "    var2roles = DefaultDict(list)\n",
    "    var2name = {}\n",
    "    for match in matches:\n",
    "        if len(match) == 2:\n",
    "            name, var = match\n",
    "            var2name[var] = name\n",
    "        elif len(match) == 3:\n",
    "            role, var1, var2 = match\n",
    "            var2roles[var2].append(role)\n",
    "\n",
    "    for var, roles in var2roles.items():\n",
    "        if var not in var2name:\n",
    "            continue\n",
    "        name = var2name[var]\n",
    "        for role in roles:\n",
    "            data.add((name, role))\n",
    "\n",
    "\n",
    "    # Step 5: Return `data`:\n",
    "    ##### YOUR CODE HERE\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60f3e98e-78f2-4096-b5df-db38700997dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_propername_role(func):\n",
    "    examples = [\n",
    "        # Standard case:\n",
    "        (\n",
    "            \"Bella ( 7 ) ; smile ( 4 ) AND agent ( 4 , 7 )\",\n",
    "            {(\"Bella\", \"agent\")}\n",
    "        ),\n",
    "        # No binding:\n",
    "        (\n",
    "            \"Riley ( 37 ) ; theme ( 4 , 7 )\",\n",
    "            set()\n",
    "        ),\n",
    "        # Two tokens of the same name referring to different entities:\n",
    "        (\n",
    "            \"Riley ( 37 ) ; Riley ( 4 ) ; theme ( 1 , 37 ) AND agent ( 1 , 4 )\",\n",
    "            {(\"Riley\", \"theme\"), (\"Riley\", \"agent\")},\n",
    "        ),\n",
    "        # Two names:\n",
    "        (\n",
    "            \"Riley ( 4 ) ; Emma ( 243 ) ; recipient ( 6 , 4 ) AND agent ( 6 , 243 )\",\n",
    "            {(\"Riley\", \"recipient\"), (\"Emma\", \"agent\")},\n",
    "        ),\n",
    "        # One name binding into multiple role expressions:\n",
    "        (\n",
    "            \"Riley ( 4 ) ; agent ( 6 , 4 ) AND theme ( 6 , 4 )\",\n",
    "            {(\"Riley\", \"theme\"), (\"Riley\", \"agent\")},\n",
    "        ),\n",
    "        # Nothing to match:\n",
    "        (\n",
    "            \"no proper names\",\n",
    "            set()\n",
    "        )\n",
    "    ]\n",
    "    errcount = 0\n",
    "    for ex, expected in examples:\n",
    "        result = func(ex)\n",
    "        if expected != result:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`:\"\n",
    "                  f\"\\n\\tInput: {ex}\"\n",
    "                  f\"\\n\\tExpected: {expected}\"\n",
    "                  f\"\\n\\tGot: {result}\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01c1d893-6e10-4913-8852-b0df7da1eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `get_propername_role`\n"
     ]
    }
   ],
   "source": [
    "test_get_propername_role(get_propername_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7908627-e0ac-4f97-bfd9-55a83ba70d3a",
   "metadata": {},
   "source": [
    "### Task 2: Finding challenging names [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab578426-4f74-4e93-879c-e40d8ab92fc7",
   "metadata": {},
   "source": [
    "You can now use your code to find the names that will be the most challenging because their train/gen roles are disjoint. To do this, you just need to complete the function `find_name_roles`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "728fe9a2-35a7-47d3-98b9-56a13362f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_name_roles(split_df, colname=\"output\"):\n",
    "    \"\"\"Create a map from names to dicts mapping roles to counts: the\n",
    "    number of time the name appears with role in `split_df`:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    split_df : pd.DataFrame\n",
    "        Needs to have a column called `colname`.\n",
    "    colname: str\n",
    "        Column to target with `get_propername_role`. Default: \"output\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `defaultdict` mapping names to roles to counts\n",
    "    \"\"\"\n",
    "    # This is a convenient way to create a multidimensional count dict:\n",
    "    # You can access it out of the box as `all_roles[key1][key2] += 1`.\n",
    "    all_roles = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "    # Apply `get_propername_role` to every value in the target column\n",
    "    # and aggregate the results into `all_roles`:\n",
    "    ##### YOUR CODE HERE\n",
    "    for s in split_df[colname]:\n",
    "        for name, role in get_propername_role(s):\n",
    "            all_roles[name][role] += 1\n",
    "\n",
    "\n",
    "\n",
    "    # Return `all_roles`:\n",
    "    return all_roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57613848-3acd-4114-b5f0-49374d7e4c5b",
   "metadata": {},
   "source": [
    "A quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72997def-1245-4c25-98f6-c7a601e35593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find_name_roles(func):\n",
    "    df = pd.DataFrame({\n",
    "        \"tester\": [\n",
    "            \"Bella ( 7 ) ; agent ( 4 , 7 )\",\n",
    "            \"Bella ( 7 ) ; agent ( 4 , 7 )\",\n",
    "            \"Riley ( 37 ) ; agent ( 4 , 37 )\",\n",
    "            \"Riley ( 3 ) ; theme ( 4 , 3 )\",\n",
    "            \"Emma ( 37 ) ; theme ( 4 , 7 )\"\n",
    "        ]})\n",
    "    expected = {\n",
    "        \"Bella\": {\"agent\": 2},\n",
    "        \"Riley\": {\"agent\": 1, \"theme\": 1}\n",
    "    }\n",
    "    result = func(df, colname=\"tester\")\n",
    "    if result != expected:\n",
    "        print(f\"Error for `{func.__name__}`:\"\n",
    "              f\"\\n\\tExpected:{expected}\"\n",
    "              f\"\\n\\tGot: {result}\")\n",
    "    else:\n",
    "        print(f\"No errors found for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb1e75e4-d5f0-4181-85d9-73b9d8b1db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found for `find_name_roles`\n"
     ]
    }
   ],
   "source": [
    "test_find_name_roles(find_name_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532c822-d02f-4930-b119-d167ee797384",
   "metadata": {},
   "source": [
    "Once the test passes, this analysis should be informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb0c22b2-845e-41b8-a958-e5cd9628bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', defaultdict(int, {'theme': 2})),\n",
       " ('Lina', defaultdict(int, {'agent': 1})),\n",
       " ('Jayden', defaultdict(int, {'agent': 34, 'recipient': 14}))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_roles = find_name_roles(dataset['train'])\n",
    "\n",
    "sorted(train_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ryan', defaultdict(int, {'agent': 6})),\n",
       " ('Grayson', defaultdict(int, {'agent': 5})),\n",
       " ('Lincoln', defaultdict(int, {'recipient': 5}))]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_roles = find_name_roles(dataset['dev'])\n",
    "\n",
    "sorted(dev_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Skylar', defaultdict(int, {'agent': 5})),\n",
       " ('Christopher', defaultdict(int, {'agent': 2})),\n",
       " ('Joshua', defaultdict(int, {'agent': 4}))]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roles = find_name_roles(dataset['test'])\n",
    "\n",
    "sorted(test_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3dc45e2a-78ef-46fd-8119-e054c58b148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', defaultdict(int, {'agent': 1000})),\n",
       " ('Lina', defaultdict(int, {'theme': 1000})),\n",
       " ('Paula', defaultdict(int, {'agent': 1000, 'theme': 1000}))]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_roles = find_name_roles(dataset[\"gen\"])\n",
    "\n",
    "sorted(gen_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9338e56-1171-48f0-ab8a-0c556d2dfdbf",
   "metadata": {},
   "source": [
    "We will return to these troublemakers in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517a076-72b5-4837-8898-fef1f8339657",
   "metadata": {},
   "source": [
    "## Pretrained ReCOGS models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0076aa3-9eea-475d-aea4-b7653a865120",
   "metadata": {},
   "source": [
    "We launch now into an extended interlude before Question 2. For Question 2, you will work with a ReCOGS model that we trained for you. This interlude presents the code needed to work with this model. We are exposing these details to you in case you want to use this code to train or fine-tune your own models for your original system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3e96e-dfc8-4e75-9b24-51e7f33a781e",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43392af3-cc12-449e-9301-983a3d554737",
   "metadata": {},
   "source": [
    "Here is a function for creating Hugging Face `PreTrainedTokenizerFast` tokenizers based on a provided vocab file. It pretty much just splits on whitespace and adds special tokens. Chris originally planned to have writing this be a homework question, but it turned out to be very difficult and confusing for him to write, so he decided to just present it to you in the hope that it helps you with similar tasks in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de55c95c-ef3d-453f-9336-97e9e93e31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "def get_tokenizer(vocab_filename):\n",
    "    with open(vocab_filename) as f:\n",
    "        vocab = f.read().splitlines()\n",
    "    vocab_size = len(vocab)\n",
    "    vocab = dict(zip(vocab, list(range(vocab_size))))\n",
    "    tok = Tokenizer(WordLevel(vocab, unk_token='[UNK]'))\n",
    "    # This definitely needs to be done here and in the construction of\n",
    "    # `PreTrainedTokenizerFast`. Don't be tempted to \"clean this up\"!\n",
    "    tok.add_special_tokens([\"[BOS]\", \"[UNK]\", \"[PAD]\", \"[EOS]\"])\n",
    "    tok.pre_tokenizer = WhitespaceSplit()\n",
    "    tok.post_processor = TemplateProcessing(\n",
    "        single=f\"[BOS]:0 $A:0 [EOS]:0\",\n",
    "        special_tokens=[\n",
    "            (\"[BOS]\", tok.token_to_id(\"[BOS]\")),\n",
    "            (\"[EOS]\", tok.token_to_id(\"[EOS]\"))])\n",
    "    return PreTrainedTokenizerFast(\n",
    "        tokenizer_object=tok,\n",
    "        bos_token=\"[BOS]\",\n",
    "        unk_token=\"[UNK]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        eos_token=\"[EOS]\",\n",
    "        # This vital; otherwise any periods will have their leading\n",
    "        # spaces removed, which is wrong for COGS/ReCOGS.\n",
    "        clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541a47b-a3ed-421c-bb9e-59f3b5f7f2af",
   "metadata": {},
   "source": [
    "We will have separate tokens for the encoder and the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa80d0a2-4599-4212-9bdb-a6d06263a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = get_tokenizer(os.path.join(SRC_DIRNAME, \"src_vocab.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fa0fc58-7b49-4e19-98c9-369eb4b3ce64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS]', 'A', 'sailor', 'was', 'helped', '[EOS]']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_tokenizer.tokenize(\n",
    "    \"A sailor was helped\", \n",
    "    add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb21e534-1d80-4642-983b-96fa415fdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tokenizer = get_tokenizer(os.path.join(SRC_DIRNAME, \"tgt_vocab.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "474ceec8-6378-45e3-ac52-659d442f259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS]',\n",
       " 'sailor',\n",
       " '(',\n",
       " '53',\n",
       " ')',\n",
       " ';',\n",
       " 'help',\n",
       " '(',\n",
       " '7',\n",
       " ')',\n",
       " 'AND',\n",
       " 'theme',\n",
       " '(',\n",
       " '7',\n",
       " ',',\n",
       " '53',\n",
       " ')',\n",
       " '[EOS]']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tokenizer.tokenize(\n",
    "    \"sailor ( 53 ) ; help ( 7 ) AND theme ( 7 , 53 )\", \n",
    "    add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25600c63-2c1f-47e7-82ed-a9f5eacb73b7",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ede76-83b6-4573-8067-f50dfc97e5dd",
   "metadata": {},
   "source": [
    "Next is a dataset utility. Chris was originally going to have you write this yourselves, since it is useful to know how to write these utilities, and the task is really just to use our tokenizers appropriately. However, since `collate_fn` has to be a static method with fixed arguments, we can't easily pass in these tokenizers to it! As a result, we have to do all the tokenization at once ahead of time and then redo all the masking work for each batch. So Chris did this for you in the hope that this will be useful to you in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2857b954-c426-4f47-a9c3-10761203883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class RecogsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, enc_tokenizer, dec_tokenizer, X, y=None):\n",
    "        self.X = [enc_tokenizer.encode(s) for s in X]\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = [dec_tokenizer.encode(s) for s in y]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Unfortunately, we can't pass the tokenizer in as an argument\n",
    "        to this method, since it is a static method, so we need to do\n",
    "        the work of creating the necessary attention masks.\"\"\"\n",
    "        def get_pad_and_mask(vals):\n",
    "            lens = [len(i) for i in vals]\n",
    "            maxlen = max(lens)\n",
    "            pad = []\n",
    "            mask = []\n",
    "            for ex, length in zip(vals, lens):\n",
    "                diff = maxlen - length\n",
    "                pad.append(ex + ([0] * diff))\n",
    "                mask.append(([1] * length) + ([0] * diff))\n",
    "            return torch.tensor(pad), torch.tensor(mask)\n",
    "        batch_elements = list(zip(*batch))\n",
    "        X = batch_elements[0]\n",
    "        X_pad, X_mask = get_pad_and_mask(X)\n",
    "        if len(batch_elements) == 1:\n",
    "            return X_pad, X_mask\n",
    "        else:\n",
    "            y = batch_elements[1]\n",
    "            y_pad, y_mask = get_pad_and_mask(y)\n",
    "            # Repeat `y_pad` because our optimizer expects to find\n",
    "            # labels in final position. These will not be used because\n",
    "            # Hugging Face will calculate the loss for us.\n",
    "            return X_pad, X_mask, y_pad, y_mask, y_pad\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return (self.X[idx],)\n",
    "        else:\n",
    "            return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3021faf-dfa6-4d89-9a39-5b4546ac2008",
   "metadata": {},
   "source": [
    "The following just illustrate how to work with the above utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3586efad-f12d-4811-8345-e7b18fc46ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dataset = RecogsDataset(\n",
    "    enc_tokenizer,\n",
    "    dec_tokenizer,\n",
    "    dataset['train'].input.head(20),\n",
    "    y=dataset['train'].output.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b80b9ddc-cc02-4b0c-863d-8453fc5bf450",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dataloader = torch.utils.data.DataLoader(\n",
    "    ex_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=ex_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a08b88f4-abc9-4921-8bf6-78c9c4157198",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_batch = iter(ex_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef750fa-794c-4fe0-a27f-330377521db3",
   "metadata": {},
   "source": [
    "This will show you batches. Since `batch_size=2` for `dataloader`, this will be a tuple where each element has two lists. The structure is determined by `collate_fn` in `RecogsDataset`: \n",
    "\n",
    "`X_pad, X_mask, y_pad, y_mask, y_pad`\n",
    "\n",
    "where `y_pad` is repeated in the final position to meet the interface specifications of `torch_base_model.py`, in case you decide to train models yourself. (See details below; Hugging Face calculates the loss itself, which is ultimately nice but a bit non-standard.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "016cb2a5-869a-4860-af8a-c94e7586128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1, 115, 361, 484, 698, 247,  17,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [  1, 115, 203, 159, 124, 679, 124, 400, 355, 698, 690, 476,  17,   2]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[  1,   7, 381,   5,  11,   6,  67, 486,   5,  22,   6,  68, 177,   5,\n",
       "           22,   8,  11,   6,  68, 724,   5,  22,   8,  44,   6,  68, 288,   5,\n",
       "           44,   6,  68, 177,   5,  44,   8,  11,   6,   2,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  1,   7, 247,   5,  11,   6,  67, 655,   5,  44,   6,  67, 415,   5,\n",
       "           63,   6,  67,   7, 479,   5,  12,   6,  67, 490,   9, 207,   5,  11,\n",
       "            8,  44,   6,  68, 382,   5,  64,   6,  68, 664,   5,  64,   8,  11,\n",
       "            6,  68, 177,   5,  64,   8,  63,   6,  68, 567,   5,  64,   8,  12,\n",
       "            6,   2]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[  1,   7, 381,   5,  11,   6,  67, 486,   5,  22,   6,  68, 177,   5,\n",
       "           22,   8,  11,   6,  68, 724,   5,  22,   8,  44,   6,  68, 288,   5,\n",
       "           44,   6,  68, 177,   5,  44,   8,  11,   6,   2,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  1,   7, 247,   5,  11,   6,  67, 655,   5,  44,   6,  67, 415,   5,\n",
       "           63,   6,  67,   7, 479,   5,  12,   6,  67, 490,   9, 207,   5,  11,\n",
       "            8,  44,   6,  68, 382,   5,  64,   6,  68, 664,   5,  64,   8,  11,\n",
       "            6,  68, 177,   5,  64,   8,  63,   6,  68, 567,   5,  64,   8,  12,\n",
       "            6,   2]]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ex_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf807690-a8dd-4f8c-8053-943c60e4e295",
   "metadata": {},
   "source": [
    "### Model basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349a372-8a06-4a04-b787-2568dceb87f9",
   "metadata": {},
   "source": [
    "Now we come to the model itself. We will first load it and explore it a bit, and then we will define a nice classifier interface for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76471758-07c0-42b7-b31e-997dc2cd9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "encdec = EncoderDecoderModel.from_pretrained(f\"ReCOGS/ReCOGS-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a470ef9b-32ed-43f1-85f7-17da743a40b1",
   "metadata": {},
   "source": [
    "A single illustrative example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "666df81f-beb3-4a30-b202-1193908b78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_inputs = enc_tokenizer.batch_encode_plus(\n",
    "    [\"A rose was helped by a dog .\"], \n",
    "    return_tensors='pt')\n",
    "\n",
    "ex_outputs = dec_tokenizer.batch_encode_plus(\n",
    "    ['rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND theme ( 7 , 53 ) AND agent ( 7 , 38 )'], \n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeca365-29b8-42bb-a696-cc9bcb6dec7d",
   "metadata": {},
   "source": [
    "Here is the forward method. For training, it is vital to have `labels=` here so that the model return a loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f64f13fb-b812-445c-8a31-e76233757a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zanqiliang/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ex_rep = encdec(\n",
    "    input_ids=ex_inputs[\"input_ids\"],\n",
    "    attention_mask=ex_inputs[\"attention_mask\"],\n",
    "    labels=ex_outputs[\"input_ids\"],\n",
    "    decoder_attention_mask=ex_outputs[\"attention_mask\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "12266de7-a99d-4ec8-9d46-bdb62485495a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state']),\n",
       " tensor(0.3451, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_rep.keys(), ex_rep.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934b5a8-dfcb-4355-8355-406ee8d2d164",
   "metadata": {},
   "source": [
    "And here is how we will do generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "71339418-1d43-4e3a-a9a1-a4b55be343c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   1, 581,   5,  41,   6,  67, 328,   5,  58,   6,  67, 408,   5,\n",
       "          17,   6,  68, 664,   5,  17,   8,  41,   6,  68, 177,   5,  17,   8,\n",
       "          58,   6,   2]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_gen = encdec.generate(\n",
    "    ex_inputs['input_ids'],\n",
    "    attention_mask=ex_inputs['attention_mask'],\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=encdec.config.eos_token_id)\n",
    "\n",
    "ex_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91da0447-d244-4fd0-8a6a-1c5bec561d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS] [BOS] rose ( 37 ) ; dog ( 52 ) ; help ( 15 ) AND theme ( 15 , 37 ) AND agent ( 15 , 52 ) [EOS]']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_pred = dec_tokenizer.batch_decode(\n",
    "    ex_gen, \n",
    "    skip_special_tokens=False, \n",
    "    # Our tokenizer have this set already, but I am nervous:\n",
    "    clean_up_tokenization_spaces=False)\n",
    "\n",
    "ex_pred\n",
    "\n",
    "# \"A rose was helped by a dog .\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10a038-99b9-467c-a86d-ed82e7bd8fdc",
   "metadata": {},
   "source": [
    "### Model interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b3db7-b1f5-4fab-84b0-4b96d7ced611",
   "metadata": {},
   "source": [
    "Okay, finally, the main interface. If you do not plan to train your own models using our code, then you can treat `RecogsModel` as an interface and not worry about these details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b17643dd-35bc-4e38-99e4-a61d47d3ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_model_base import TorchModelBase\n",
    "import torch.nn as nn\n",
    "from transformers import EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599c05a-1be6-447c-a931-2cadd1112758",
   "metadata": {},
   "source": [
    "As I mentioned above, Hugging Face `EncoderDecoderModel` instances will calculate a loss internally if you provide them with `labels`. Normally, one's optimization loop would need to do this manually. In order to rely on Hugging Face and still use the trainer in `torch_model_base.py`, we define this simple loss that just takes in model outputs and labels and returns `outputs.loss`. The labels argument is present for compatibility; it was already used internally to get the value of `outputs.loss` and so can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f69d742e-58c2-4993-b6d8-6f18b3d157f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecogsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reduction = \"mean\"\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        \"\"\"`labels` is ignored, as it was already used to assign a\n",
    "        value of `outputs.loss`, and that value is all we need.\"\"\"\n",
    "        return outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27db42-46d1-436e-8870-70fdd38e1219",
   "metadata": {},
   "source": [
    "Here is a basic `nn.Module`. Its sole purpose is to organize the examples created by our `RecogsDataset` and feed them to the trained `EncoderDecoderModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "49dd0d13-41fd-4c9a-b7de-90bd2a7a1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecogsModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encdec = EncoderDecoderModel.from_pretrained(\n",
    "            f\"ReCOGS/ReCOGS-model\")\n",
    "\n",
    "        # self.encdec = EncoderDecoderModel.from_pretrained(\n",
    "        #     '../ReCOGS/results_cogs/cogs_pipeline.model.ende_transformer.lf.cogs.glove.False.seed.42/model-last/'\n",
    "        # )\n",
    "\n",
    "    def forward(self, X_pad, X_mask, y_pad, y_mask, labels=None):\n",
    "        outputs = self.encdec(\n",
    "            input_ids=X_pad, \n",
    "            attention_mask=X_mask,\n",
    "            decoder_attention_mask=y_mask,\n",
    "            labels=y_pad)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996ee6c-ef7c-4f51-b596-a1d69ecc59a2",
   "metadata": {},
   "source": [
    "And, at last, our interface. The keyword parameter `initialize=True` is the default because we are initially going to use this just for making predictions, and so we need the instance to establish all its parameters when we initialize it as opposed to waiting to do that when we call `fit` (which we may never do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: the huggingface translation task course is using MarianMTModel. For summarization task, it is using mt5. They should both have a bilingual tokenizer. They might work for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7105b19c-a8b7-44c7-9028-f62936a578b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecogsModel(TorchModelBase):\n",
    "    def __init__(self, *args,\n",
    "            initialize=True,\n",
    "            enc_vocab_filename=f\"{SRC_DIRNAME}/src_vocab.txt\",\n",
    "            dec_vocab_filename=f\"{SRC_DIRNAME}/tgt_vocab.txt\",\n",
    "            **kwargs):\n",
    "        self.enc_vocab_filename = enc_vocab_filename\n",
    "        self.dec_vocab_filename = dec_vocab_filename\n",
    "        self.enc_tokenizer = get_tokenizer(self.enc_vocab_filename)\n",
    "        self.dec_tokenizer = get_tokenizer(self.dec_vocab_filename)\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss = RecogsLoss()\n",
    "        if initialize:\n",
    "            self.initialize()\n",
    "\n",
    "    def build_graph(self):\n",
    "        return RecogsModule()\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        return RecogsDataset(\n",
    "            self.enc_tokenizer, self.dec_tokenizer, X, y=y)\n",
    "\n",
    "    def predict(self, X, device=None):\n",
    "        device = self.device if device is None else torch.device(device)\n",
    "        dataset = self.build_dataset(X)\n",
    "        dataloader = self._build_dataloader(dataset, shuffle=False)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                X_pad, X_mask = [x.to(device) for x in batch]\n",
    "                outputs = self.model.encdec.generate(\n",
    "                    X_pad,\n",
    "                    attention_mask=X_mask,\n",
    "                    max_new_tokens=512,\n",
    "                    eos_token_id=self.model.encdec.config.eos_token_id)\n",
    "                results = self.dec_tokenizer.batch_decode(\n",
    "                    outputs, \n",
    "                    skip_special_tokens=True,\n",
    "                    clean_up_tokenization_spaces=False)\n",
    "                preds += results\n",
    "        return preds\n",
    "\n",
    "    def score(self, X, y, device=None):\n",
    "        # An overall accuracy score:\n",
    "        preds = self.predict(X, device=device)\n",
    "        vals = [int(recogs_exact_match(gold, pred)) for gold, pred in zip(y, preds)]\n",
    "        return sum(vals) / len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "95d30490-b7ce-4efe-85f7-e101e3481454",
   "metadata": {},
   "outputs": [],
   "source": [
    "recogs_model = RecogsModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f41201-b28b-4352-9bcf-b62b9d977af9",
   "metadata": {},
   "source": [
    "Predictions for our first to train cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "87b99739-eb29-4876-9248-dd72eff1e926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liam ( 15 ) ; box ( 47 ) ; girl ( 35 ) ; hope ( 40 ) AND agent ( 40 , 15 ) AND ccomp ( 40 , 8 ) AND burn ( 8 ) AND theme ( 8 , 47 ) AND agent ( 8 , 35 )',\n",
       " '* donkey ( 48 ) ; * cookie ( 25 ) ; mother ( 50 ) ; lend ( 49 ) AND agent ( 49 , 48 ) AND theme ( 49 , 25 ) AND recipient ( 49 , 50 )']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recogs_model.predict(dataset['dev'].input[: 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86e9b3-4281-4c74-92e5-9288f202e881",
   "metadata": {},
   "source": [
    "## Question 2: Exploring predictions [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06170626-679b-4710-a4a2-f444c104f44b",
   "metadata": {},
   "source": [
    "Now that we are set up to use the model, we can move to Question 2. There is just one final preliminary: for ReCOGs, we want to come as close as possible to assessing systems purely on semantic criteria, as opposed to assessing their ability to predict arbitrary features of logical forms. In particular, we want predictions to be independent of the particular choice of variable names and independent of the order of conjuncts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31f1aa-26a0-41a6-a01b-0a4fe85e6367",
   "metadata": {},
   "source": [
    "### ReCOGS assessment function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9451d8-2e9d-4a3d-943f-0d06e747b12f",
   "metadata": {},
   "source": [
    "The function `recogs_exact_match` does this. It's a complex function, and so you can ignore its precise implementation details. Here are some illustrative examples to give you a feel for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "08c49a60-082e-42d0-ac75-0a606fd5a588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The precise names of bound variables do not matter:\n",
    "\n",
    "recogs_exact_match(\n",
    "    \"dog ( 4 ) AND happy ( 4 )\", \n",
    "    \"dog ( 7 ) AND happy ( 7 ) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "657bc28c-505b-4247-bcbe-dc49718dca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The order of conjuncts does not matter:\n",
    "\n",
    "recogs_exact_match(\n",
    "    \"dog ( 4 ) AND happy ( 4 )\", \n",
    "    \"happy ( 7 ) AND dog ( 7 )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a49eb573-2153-4f63-aad1-cb5ac8f2df62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consistency of variable names does matter:\n",
    "\n",
    "recogs_exact_match(\n",
    "    \"dog ( 4 ) AND happy ( 4 )\", \n",
    "    \"dog ( 4 ) AND happy ( 7 )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be2e2c-d1d1-4f44-8ca0-2ee0f23cf3ee",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b83476-d018-4b24-9126-38c3577b68de",
   "metadata": {},
   "source": [
    "Your task is to write a utility function to see how well a model does on a specific generalization category in the generalization dataset. The metric is accuracy according to `recogs_exact_match`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "378d7f44-a317-433e-befa-301cdcd16978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_assess(gen_df, model, category):\n",
    "    \"\"\"Assess `model` against the `category` examples in `gen_df`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gen_df: pd.DataFrame\n",
    "        Should be `dataset[\"gen\"]`\n",
    "    model: A `RecogsModel instance\n",
    "    category: str\n",
    "        A string from `gen_df.category`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `pd.DataFrame` limited to `category` examples and with columns\n",
    "    \"prediction\" and \"correct\" added by this function\n",
    "    \"\"\"\n",
    "    # This line is done for you because of how important it is to\n",
    "    # operate on a copy of the dataframe rather than the original!\n",
    "    cat_df = gen_df[gen_df.category == category].copy()\n",
    "\n",
    "    # Step 1: Add a column called \"prediction\" to `cat_df`. This should\n",
    "    # give the predicted LFs:\n",
    "    ##### YOUR CODE HERE\n",
    "    cat_df[\"prediction\"] = model.predict(cat_df.input)\n",
    "\n",
    "\n",
    "\n",
    "    # Step 2: Add a column \"correct\" that says whether the prediction\n",
    "    # and the gold output are the same. Must use `recogs_exact_match`.\n",
    "    ##### YOUR CODE HERE\n",
    "    cat_df[\"correct\"] = [recogs_exact_match(gold, pred) for gold, pred in zip(cat_df.output, cat_df.prediction)]\n",
    "\n",
    "\n",
    "    # Step 3: Return the `pd.DataFrame` `cat_df`:\n",
    "    ##### YOUR CODE HERE\n",
    "    return cat_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>A child tolerated the cake on the road in the house in a car beside a stage on the pedestal on the chair on a bed on the yacht in a bottle on the futon on the table on the canvas .</td>\n",
       "      <td>child ( 23 ) ; * cake ( 6 ) ; * road ( 51 ) ; * house ( 30 ) ; car ( 49 ) ; stage ( 18 ) ; * pedestal ( 52 ) ; * chair ( 29 ) ; bed ( 31 ) ; * yacht ( 21 ) ; bottle ( 38 ) ; * futon ( 3 ) ; * table ( 35 ) ; * canvas ( 44 ) ; nmod . on ( 6 , 51 ) AND nmod . in ( 51 , 30 ) AND nmod . in ( 30 , 49 ) AND nmod . beside ( 49 , 18 ) AND nmod . on ( 18 , 52 ) AND nmod . on ( 52 , 29 ) AND nmod . on ( 29 , 31 ) AND nmod . on ( 31 , 21 ) AND nmod . in ( 21 , 38 ) AND nmod . on ( 38 , 3 ) AND nmod . on ( 3 , 35 ) AND nmod . on ( 35 , 44 ) AND tolerate ( 26 ) AND agent ( 26 , 23 ) AND theme ( 26 , 6 )</td>\n",
       "      <td>pp_recursion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>Emma liked that a cockroach slept .</td>\n",
       "      <td>Emma ( 31 ) ; cockroach ( 42 ) ; like ( 53 ) AND agent ( 53 , 31 ) AND ccomp ( 53 , 23 ) AND sleep ( 23 ) AND agent ( 23 , 42 )</td>\n",
       "      <td>obj_to_subj_common</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Luna hoped that the hippo ate .</td>\n",
       "      <td>Luna ( 39 ) ; * hippo ( 8 ) ; hope ( 50 ) AND agent ( 50 , 39 ) AND ccomp ( 50 , 28 ) AND eat ( 28 ) AND agent ( 28 , 8 )</td>\n",
       "      <td>only_seen_as_unacc_subj_as_obj_omitted_transitive_subj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18322</th>\n",
       "      <td>The fly squeezed the hero .</td>\n",
       "      <td>* fly ( 1 ) ; * hero ( 45 ) ; squeeze ( 39 ) AND agent ( 39 , 1 ) AND theme ( 39 , 45 )</td>\n",
       "      <td>passive_to_active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>The monster shattered Evelyn .</td>\n",
       "      <td>* monster ( 14 ) ; Evelyn ( 25 ) ; shatter ( 41 ) AND agent ( 41 , 14 ) AND theme ( 41 , 25 )</td>\n",
       "      <td>unacc_to_transitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      input  \\\n",
       "1623   A child tolerated the cake on the road in the house in a car beside a stage on the pedestal on the chair on a bed on the yacht in a bottle on the futon on the table on the canvas .   \n",
       "1657                                                                                                                                                    Emma liked that a cockroach slept .   \n",
       "98                                                                                                                                                          Luna hoped that the hippo ate .   \n",
       "18322                                                                                                                                                           The fly squeezed the hero .   \n",
       "5679                                                                                                                                                         The monster shattered Evelyn .   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     output  \\\n",
       "1623   child ( 23 ) ; * cake ( 6 ) ; * road ( 51 ) ; * house ( 30 ) ; car ( 49 ) ; stage ( 18 ) ; * pedestal ( 52 ) ; * chair ( 29 ) ; bed ( 31 ) ; * yacht ( 21 ) ; bottle ( 38 ) ; * futon ( 3 ) ; * table ( 35 ) ; * canvas ( 44 ) ; nmod . on ( 6 , 51 ) AND nmod . in ( 51 , 30 ) AND nmod . in ( 30 , 49 ) AND nmod . beside ( 49 , 18 ) AND nmod . on ( 18 , 52 ) AND nmod . on ( 52 , 29 ) AND nmod . on ( 29 , 31 ) AND nmod . on ( 31 , 21 ) AND nmod . in ( 21 , 38 ) AND nmod . on ( 38 , 3 ) AND nmod . on ( 3 , 35 ) AND nmod . on ( 35 , 44 ) AND tolerate ( 26 ) AND agent ( 26 , 23 ) AND theme ( 26 , 6 )   \n",
       "1657                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Emma ( 31 ) ; cockroach ( 42 ) ; like ( 53 ) AND agent ( 53 , 31 ) AND ccomp ( 53 , 23 ) AND sleep ( 23 ) AND agent ( 23 , 42 )   \n",
       "98                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Luna ( 39 ) ; * hippo ( 8 ) ; hope ( 50 ) AND agent ( 50 , 39 ) AND ccomp ( 50 , 28 ) AND eat ( 28 ) AND agent ( 28 , 8 )   \n",
       "18322                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               * fly ( 1 ) ; * hero ( 45 ) ; squeeze ( 39 ) AND agent ( 39 , 1 ) AND theme ( 39 , 45 )   \n",
       "5679                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          * monster ( 14 ) ; Evelyn ( 25 ) ; shatter ( 41 ) AND agent ( 41 , 14 ) AND theme ( 41 , 25 )   \n",
       "\n",
       "                                                     category  \n",
       "1623                                             pp_recursion  \n",
       "1657                                       obj_to_subj_common  \n",
       "98     only_seen_as_unacc_subj_as_obj_omitted_transitive_subj  \n",
       "18322                                       passive_to_active  \n",
       "5679                                      unacc_to_transitive  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['gen'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "14331e44-6eb6-4c87-9930-28d6b0f1506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_category_assess(func):\n",
    "    testmod = RecogsModel()\n",
    "    samp_df = dataset['gen'].head(150)\n",
    "    examples = [\n",
    "        (\"active_to_passive\", 0.80),\n",
    "        (\"unacc_to_transitive\", 0.86),\n",
    "        (\"obj_to_subj_proper\", 0.78)\n",
    "    ]\n",
    "    result_df = func(samp_df, testmod, \"active_to_passive\")\n",
    "    if not isinstance(result_df, pd.DataFrame):\n",
    "        print(f\"Error `{func.__name__}`: \"\n",
    "              \"Return value should be a `pd.DataFrame`\")\n",
    "        return\n",
    "    errcount = 0\n",
    "    for colname in (\"input\", \"output\", \"category\", \"prediction\", \"correct\"):\n",
    "        if colname not in result_df.columns:\n",
    "            errcount += 1\n",
    "            print(f\"Error `{func.__name__}`: column '{colname}' is missing\")\n",
    "    if errcount != 0:\n",
    "        return\n",
    "    expected_len = 5\n",
    "    result_len = result_df.shape[0]\n",
    "    if not result_df.shape[0] == expected_len:\n",
    "        print(f\"Error `{func.__name__}`: \"\n",
    "              f\"Expected {expected_len} results, got {result_len}.\")\n",
    "        return\n",
    "    errcount = 0\n",
    "    for cat, expected in examples:\n",
    "        result_df = func(samp_df, testmod, cat)\n",
    "        result = result_df.correct.sum() / result_df.shape[0]\n",
    "        result = round(result, 2)\n",
    "        if result != expected:\n",
    "            errcount += 1\n",
    "            print(f\"Error `{func.__name__}` with category {cat}: \"\n",
    "                  f\"Expected acc {expected}, got {result}\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e3a178d8-b45b-411c-8995-3e6869322565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors for `category_assess`\n"
     ]
    }
   ],
   "source": [
    "test_category_assess(category_assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fcde66-9b8c-4ca6-947b-2bb8a98a3671",
   "metadata": {},
   "source": [
    "Question 1 above might lead you to expect that our model will struggle with examples in which proper names appear with totally unfamiliar roles. For that question, you wrote `get_propername_role` to get `(name, role)` pairs from examples and `find_name_roles` to do analyses with that function. We can now run that same analysis on our errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "67a5305d-4144-45a2-91c4-75e64021fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df = dataset['gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ede22c2d-6fe3-4dbe-ab0d-ababd9d48d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on your computer, this could take a while. On a relatively\n",
    "# new Apple laptop, it took about 3 minutes. Colab will be much more\n",
    "# variable in the time it takes, depending on what kind of instance\n",
    "# you are running.\n",
    "\n",
    "pred_df = category_assess(gen_df, recogs_model, \"obj_to_subj_proper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfda72-8d80-4137-9f34-ec39d3e2de95",
   "metadata": {},
   "source": [
    "Extract the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "974d1a73-a08b-478f-b463-9c079836755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = pred_df[pred_df.correct == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e4376-ce08-417c-abcd-d414cbc8d2c4",
   "metadata": {},
   "source": [
    "Use `find_name_roles` to get the role distribution in the error set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "56f4fbcb-e9ad-4789-9c8c-f0d66af74426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', defaultdict(int, {'agent': 64})),\n",
       " ('Ava', defaultdict(int, {'agent': 1})),\n",
       " ('Skylar', defaultdict(int, {'recipient': 1}))]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_roles = find_name_roles(err_df, colname=\"output\")\n",
    "sorted(err_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab221a-f50d-42af-a4ec-c59fcd7eef31",
   "metadata": {},
   "source": [
    "It's our old friend Charlie – in training, always a theme; in the generalization tests, always an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>category</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William tolerated that Charlie fed the cake on the stage to the boy .</td>\n",
       "      <td>William ( 4 ) ; Charlie ( 3 ) ; * cake ( 27 ) ; * stage ( 31 ) ; * boy ( 17 ) ; nmod . on ( 27 , 31 ) AND tolerate ( 24 ) AND agent ( 24 , 4 ) AND ccomp ( 24 , 6 ) AND feed ( 6 ) AND agent ( 6 , 3 ) AND theme ( 6 , 27 ) AND recipient ( 6 , 17 )</td>\n",
       "      <td>obj_to_subj_proper</td>\n",
       "      <td>William ( 24 ) ; Charlie ( 1 ) ; * cake ( 31 ) ; * stage ( 49 ) ; * boy ( 45 ) ; nmod . on ( 31 , 49 ) AND tolerate ( 51 ) AND agent ( 51 , 24 ) AND ccomp ( 51 , 31 ) AND feed ( 31 ) AND agent ( 31 , 1 ) AND theme ( 31 , 31 ) AND recipient ( 31 , 45 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Charlie gave William the purse on the stage .</td>\n",
       "      <td>Charlie ( 51 ) ; William ( 32 ) ; * purse ( 8 ) ; * stage ( 36 ) ; nmod . on ( 8 , 36 ) AND give ( 59 ) AND agent ( 59 , 51 ) AND recipient ( 59 , 32 ) AND theme ( 59 , 8 )</td>\n",
       "      <td>obj_to_subj_proper</td>\n",
       "      <td>Charlie ( 22 ) ; William ( 20 ) ; * purse ( 31 ) ; * stage ( 23 ) ; nmod . on ( 31 , 23 ) AND give ( 20 ) AND agent ( 20 , 22 ) AND recipient ( 20 , 20 ) AND theme ( 20 , 31 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Ava thought that the boy supported that Charlie studied .</td>\n",
       "      <td>Ava ( 52 ) ; * boy ( 35 ) ; Charlie ( 54 ) ; think ( 36 ) AND agent ( 36 , 52 ) AND ccomp ( 36 , 7 ) AND support ( 7 ) AND agent ( 7 , 35 ) AND ccomp ( 7 , 43 ) AND study ( 43 ) AND agent ( 43 , 54 )</td>\n",
       "      <td>obj_to_subj_proper</td>\n",
       "      <td>Ava ( 22 ) ; * boy ( 23 ) ; Charlie ( 0 ) ; think ( 25 ) AND agent ( 25 , 22 ) AND ccomp ( 25 , 20 ) AND support ( 20 ) AND agent ( 20 , 23 ) AND ccomp ( 20 , 46 ) AND study ( 46 ) AND theme ( 46 , 0 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Charlie served a horse the drink on a computer on a bed .</td>\n",
       "      <td>Charlie ( 52 ) ; horse ( 38 ) ; * drink ( 12 ) ; computer ( 3 ) ; bed ( 17 ) ; nmod . on ( 12 , 3 ) AND nmod . on ( 3 , 17 ) AND serve ( 19 ) AND agent ( 19 , 52 ) AND recipient ( 19 , 38 ) AND theme ( 19 , 12 )</td>\n",
       "      <td>obj_to_subj_proper</td>\n",
       "      <td>Charlie ( 10 ) ; horse ( 17 ) ; * drink ( 26 ) ; computer ( 9 ) ; bed ( 35 ) ; nmod . on ( 26 , 9 ) AND nmod . on ( 9 , 33 ) AND serve ( 17 ) AND agent ( 17 , 10 ) AND recipient ( 17 , 17 ) AND theme ( 17 , 26 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Charlie gave the donut in a cup beside the stage to Skylar .</td>\n",
       "      <td>Charlie ( 24 ) ; * donut ( 10 ) ; cup ( 22 ) ; * stage ( 42 ) ; Skylar ( 46 ) ; nmod . in ( 10 , 22 ) AND nmod . beside ( 22 , 42 ) AND give ( 34 ) AND agent ( 34 , 24 ) AND theme ( 34 , 10 ) AND recipient ( 34 , 46 )</td>\n",
       "      <td>obj_to_subj_proper</td>\n",
       "      <td>Charlie ( 22 ) ; * donut ( 12 ) ; cup ( 56 ) ; * stage ( 56 ) ; Skylar ( 34 ) ; nmod . in ( 12 , 56 ) AND nmod . beside ( 56 , 48 ) AND give ( 18 ) AND agent ( 18 , 22 ) AND theme ( 18 , 12 ) AND recipient ( 18 , 34 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      input  \\\n",
       "6     William tolerated that Charlie fed the cake on the stage to the boy .   \n",
       "101                           Charlie gave William the purse on the stage .   \n",
       "188               Ava thought that the boy supported that Charlie studied .   \n",
       "421               Charlie served a horse the drink on a computer on a bed .   \n",
       "1078           Charlie gave the donut in a cup beside the stage to Skylar .   \n",
       "\n",
       "                                                                                                                                                                                                                                                    output  \\\n",
       "6     William ( 4 ) ; Charlie ( 3 ) ; * cake ( 27 ) ; * stage ( 31 ) ; * boy ( 17 ) ; nmod . on ( 27 , 31 ) AND tolerate ( 24 ) AND agent ( 24 , 4 ) AND ccomp ( 24 , 6 ) AND feed ( 6 ) AND agent ( 6 , 3 ) AND theme ( 6 , 27 ) AND recipient ( 6 , 17 )   \n",
       "101                                                                           Charlie ( 51 ) ; William ( 32 ) ; * purse ( 8 ) ; * stage ( 36 ) ; nmod . on ( 8 , 36 ) AND give ( 59 ) AND agent ( 59 , 51 ) AND recipient ( 59 , 32 ) AND theme ( 59 , 8 )   \n",
       "188                                                Ava ( 52 ) ; * boy ( 35 ) ; Charlie ( 54 ) ; think ( 36 ) AND agent ( 36 , 52 ) AND ccomp ( 36 , 7 ) AND support ( 7 ) AND agent ( 7 , 35 ) AND ccomp ( 7 , 43 ) AND study ( 43 ) AND agent ( 43 , 54 )   \n",
       "421                                    Charlie ( 52 ) ; horse ( 38 ) ; * drink ( 12 ) ; computer ( 3 ) ; bed ( 17 ) ; nmod . on ( 12 , 3 ) AND nmod . on ( 3 , 17 ) AND serve ( 19 ) AND agent ( 19 , 52 ) AND recipient ( 19 , 38 ) AND theme ( 19 , 12 )   \n",
       "1078                             Charlie ( 24 ) ; * donut ( 10 ) ; cup ( 22 ) ; * stage ( 42 ) ; Skylar ( 46 ) ; nmod . in ( 10 , 22 ) AND nmod . beside ( 22 , 42 ) AND give ( 34 ) AND agent ( 34 , 24 ) AND theme ( 34 , 10 ) AND recipient ( 34 , 46 )   \n",
       "\n",
       "                category  \\\n",
       "6     obj_to_subj_proper   \n",
       "101   obj_to_subj_proper   \n",
       "188   obj_to_subj_proper   \n",
       "421   obj_to_subj_proper   \n",
       "1078  obj_to_subj_proper   \n",
       "\n",
       "                                                                                                                                                                                                                                                       prediction  \\\n",
       "6     William ( 24 ) ; Charlie ( 1 ) ; * cake ( 31 ) ; * stage ( 49 ) ; * boy ( 45 ) ; nmod . on ( 31 , 49 ) AND tolerate ( 51 ) AND agent ( 51 , 24 ) AND ccomp ( 51 , 31 ) AND feed ( 31 ) AND agent ( 31 , 1 ) AND theme ( 31 , 31 ) AND recipient ( 31 , 45 )   \n",
       "101                                                                               Charlie ( 22 ) ; William ( 20 ) ; * purse ( 31 ) ; * stage ( 23 ) ; nmod . on ( 31 , 23 ) AND give ( 20 ) AND agent ( 20 , 22 ) AND recipient ( 20 , 20 ) AND theme ( 20 , 31 )   \n",
       "188                                                     Ava ( 22 ) ; * boy ( 23 ) ; Charlie ( 0 ) ; think ( 25 ) AND agent ( 25 , 22 ) AND ccomp ( 25 , 20 ) AND support ( 20 ) AND agent ( 20 , 23 ) AND ccomp ( 20 , 46 ) AND study ( 46 ) AND theme ( 46 , 0 )   \n",
       "421                                           Charlie ( 10 ) ; horse ( 17 ) ; * drink ( 26 ) ; computer ( 9 ) ; bed ( 35 ) ; nmod . on ( 26 , 9 ) AND nmod . on ( 9 , 33 ) AND serve ( 17 ) AND agent ( 17 , 10 ) AND recipient ( 17 , 17 ) AND theme ( 17 , 26 )   \n",
       "1078                                    Charlie ( 22 ) ; * donut ( 12 ) ; cup ( 56 ) ; * stage ( 56 ) ; Skylar ( 34 ) ; nmod . in ( 12 , 56 ) AND nmod . beside ( 56 , 48 ) AND give ( 18 ) AND agent ( 18 , 22 ) AND theme ( 18 , 12 ) AND recipient ( 18 , 34 )   \n",
       "\n",
       "      correct  \n",
       "6       False  \n",
       "101     False  \n",
       "188     False  \n",
       "421     False  \n",
       "1078    False  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred_df):\n",
    "    \"\"\"Compute the accuracy of `pred_df`.\"\"\"\n",
    "    return pred_df.correct.sum() / pred_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.60000000000001"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.8"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = category_assess(gen_df, recogs_model, \"subj_to_obj_proper\")\n",
    "get_accuracy((pred_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lina', defaultdict(int, {'theme': 132})),\n",
       " ('Abigail', defaultdict(int, {'recipient': 1})),\n",
       " ('Chloe', defaultdict(int, {'recipient': 1}))]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df = pred_df[pred_df.correct == False]\n",
    "err_roles = find_name_roles(err_df, colname=\"output\")\n",
    "sorted(err_roles.items(), key=lambda x: len(x[1]))[: 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's our old friend Lina – in training, always a agent; in the generalization tests, always a theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>category</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Noah gave Elizabeth Lina .</td>\n",
       "      <td>Noah ( 49 ) ; Elizabeth ( 38 ) ; Lina ( 42 ) ; give ( 3 ) AND agent ( 3 , 49 ) AND recipient ( 3 , 38 ) AND theme ( 3 , 42 )</td>\n",
       "      <td>subj_to_obj_proper</td>\n",
       "      <td>Noah ( 11 ) ; Elizabeth ( 15 ) ; give ( 38 ) AND agent ( 38 , 11 ) AND recipient ( 38 , 15 ) AND theme ( 38 , 15 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Dylan believed that a girl sent the human Lina .</td>\n",
       "      <td>Dylan ( 51 ) ; girl ( 46 ) ; * human ( 49 ) ; Lina ( 5 ) ; believe ( 18 ) AND agent ( 18 , 51 ) AND ccomp ( 18 , 14 ) AND send ( 14 ) AND agent ( 14 , 46 ) AND recipient ( 14 , 49 ) AND theme ( 14 , 5 )</td>\n",
       "      <td>subj_to_obj_proper</td>\n",
       "      <td>Dylan ( 18 ) ; girl ( nmod . on ( 54 ) AND believe ( 26 ) AND agent ( 26 , 18 ) AND ccomp ( 26 , 46 ) AND send ( 46 ) AND agent ( 46 , 18 ) AND recipient ( 46 , 54 ) AND theme ( 46 , 54 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>The buyer forwarded Emma Lina .</td>\n",
       "      <td>* buyer ( 52 ) ; Emma ( 24 ) ; Lina ( 6 ) ; forward ( 38 ) AND agent ( 38 , 52 ) AND recipient ( 38 , 24 ) AND theme ( 38 , 6 )</td>\n",
       "      <td>subj_to_obj_proper</td>\n",
       "      <td>* buyer ( 7 ) ; Emma ( 38 ) ; forward ( 37 ) AND agent ( 37 , 7 ) AND recipient ( 37 , 38 ) AND theme ( 37 , 38 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Emma tolerated that a boy passed Abigail Lina .</td>\n",
       "      <td>Emma ( 6 ) ; boy ( 2 ) ; Abigail ( 39 ) ; Lina ( 37 ) ; tolerate ( 52 ) AND agent ( 52 , 6 ) AND ccomp ( 52 , 0 ) AND pass ( 0 ) AND agent ( 0 , 2 ) AND recipient ( 0 , 39 ) AND theme ( 0 , 37 )</td>\n",
       "      <td>subj_to_obj_proper</td>\n",
       "      <td>Emma ( 25 ) ; boy ( 43 ) ; Abigail ( 40 ) ; tolerate ( 28 ) AND agent ( 28 , 25 ) AND ccomp ( 28 , 16 ) AND pass ( 16 ) AND agent ( 16 , 43 ) AND recipient ( 16 , 40 ) AND theme ( 16 , 40 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>A girl sold Lina to Chloe .</td>\n",
       "      <td>girl ( 15 ) ; Lina ( 37 ) ; Chloe ( 1 ) ; sell ( 2 ) AND agent ( 2 , 15 ) AND theme ( 2 , 37 ) AND recipient ( 2 , 1 )</td>\n",
       "      <td>subj_to_obj_proper</td>\n",
       "      <td>girl ( 31 ) ; Lina ( 29 ) ; sell ( 8 ) AND agent ( 8 , 31 ) AND theme ( 8 , 29 ) AND recipient ( 8 , 29 )</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "196                         Noah gave Elizabeth Lina .   \n",
       "387   Dylan believed that a girl sent the human Lina .   \n",
       "418                    The buyer forwarded Emma Lina .   \n",
       "863    Emma tolerated that a boy passed Abigail Lina .   \n",
       "1249                       A girl sold Lina to Chloe .   \n",
       "\n",
       "                                                                                                                                                                                                          output  \\\n",
       "196                                                                                 Noah ( 49 ) ; Elizabeth ( 38 ) ; Lina ( 42 ) ; give ( 3 ) AND agent ( 3 , 49 ) AND recipient ( 3 , 38 ) AND theme ( 3 , 42 )   \n",
       "387   Dylan ( 51 ) ; girl ( 46 ) ; * human ( 49 ) ; Lina ( 5 ) ; believe ( 18 ) AND agent ( 18 , 51 ) AND ccomp ( 18 , 14 ) AND send ( 14 ) AND agent ( 14 , 46 ) AND recipient ( 14 , 49 ) AND theme ( 14 , 5 )   \n",
       "418                                                                              * buyer ( 52 ) ; Emma ( 24 ) ; Lina ( 6 ) ; forward ( 38 ) AND agent ( 38 , 52 ) AND recipient ( 38 , 24 ) AND theme ( 38 , 6 )   \n",
       "863           Emma ( 6 ) ; boy ( 2 ) ; Abigail ( 39 ) ; Lina ( 37 ) ; tolerate ( 52 ) AND agent ( 52 , 6 ) AND ccomp ( 52 , 0 ) AND pass ( 0 ) AND agent ( 0 , 2 ) AND recipient ( 0 , 39 ) AND theme ( 0 , 37 )   \n",
       "1249                                                                                      girl ( 15 ) ; Lina ( 37 ) ; Chloe ( 1 ) ; sell ( 2 ) AND agent ( 2 , 15 ) AND theme ( 2 , 37 ) AND recipient ( 2 , 1 )   \n",
       "\n",
       "                category  \\\n",
       "196   subj_to_obj_proper   \n",
       "387   subj_to_obj_proper   \n",
       "418   subj_to_obj_proper   \n",
       "863   subj_to_obj_proper   \n",
       "1249  subj_to_obj_proper   \n",
       "\n",
       "                                                                                                                                                                                         prediction  \\\n",
       "196                                                                              Noah ( 11 ) ; Elizabeth ( 15 ) ; give ( 38 ) AND agent ( 38 , 11 ) AND recipient ( 38 , 15 ) AND theme ( 38 , 15 )   \n",
       "387     Dylan ( 18 ) ; girl ( nmod . on ( 54 ) AND believe ( 26 ) AND agent ( 26 , 18 ) AND ccomp ( 26 , 46 ) AND send ( 46 ) AND agent ( 46 , 18 ) AND recipient ( 46 , 54 ) AND theme ( 46 , 54 )   \n",
       "418                                                                               * buyer ( 7 ) ; Emma ( 38 ) ; forward ( 37 ) AND agent ( 37 , 7 ) AND recipient ( 37 , 38 ) AND theme ( 37 , 38 )   \n",
       "863   Emma ( 25 ) ; boy ( 43 ) ; Abigail ( 40 ) ; tolerate ( 28 ) AND agent ( 28 , 25 ) AND ccomp ( 28 , 16 ) AND pass ( 16 ) AND agent ( 16 , 43 ) AND recipient ( 16 , 40 ) AND theme ( 16 , 40 )   \n",
       "1249                                                                                      girl ( 31 ) ; Lina ( 29 ) ; sell ( 8 ) AND agent ( 8 , 31 ) AND theme ( 8 , 29 ) AND recipient ( 8 , 29 )   \n",
       "\n",
       "      correct  \n",
       "196     False  \n",
       "387     False  \n",
       "418     False  \n",
       "863     False  \n",
       "1249    False  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = category_assess(gen_df, recogs_model, \"obj_pp_to_subj_pp\")\n",
    "get_accuracy((pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a19b17-f58a-4a40-a07a-71f362dd33d1",
   "metadata": {},
   "source": [
    "## Question 3: In-context learning with DSP [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9489b4a-849d-4b00-835a-a5a6cc6f61d5",
   "metadata": {},
   "source": [
    "For this question, we are going to switch gears, from using our trained ReCOGS model to seeing whether we can get traction on this problem using only in-context learning. This question is meant to be very straightforward – our sole goal is to get you to the point where you have a working DSP program that you can build on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9a648-1535-4f31-945f-1488a5883a70",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae6c14-4aab-41c3-9d12-177c5de38a09",
   "metadata": {},
   "source": [
    "Standard set-up for DSP, but we don't need a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e4148343-7182-4e75-be98-f40481e8f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import os\n",
    "import dsp\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_path = '.'\n",
    "\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')  # or replace with your API key (optional)\n",
    "\n",
    "cohere_key = os.getenv('COHERE_API_KEY')  # or replace with your API key (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8932c-2916-4d35-b05f-533713414c0d",
   "metadata": {},
   "source": [
    "Our language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1d1d1d00-4589-45d3-86f3-d6c1b81e8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for Cohere: command-medium-nightly, command-xlarge-nightly\n",
    "lm = dsp.Cohere(model='command-xlarge-nightly', api_key=cohere_key)\n",
    "\n",
    "# Options for OpenAI:\n",
    "# [d[\"root\"] for d in openai.Model.list()[\"data\"]]\n",
    "# lm = dsp.GPT3(model='text-davinci-001', api_key=openai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338f9bd-6f4d-4131-bd35-efadd6e2a72e",
   "metadata": {},
   "source": [
    "DSP settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "18e2cbc2-60bd-4893-8de0-5ef2ad3950f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840dbd4b-7652-4bb8-bafb-c38bd752c10e",
   "metadata": {},
   "source": [
    "### Train examples in DSP format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ceb9c5-183e-45f0-9f1b-3783b334053c",
   "metadata": {},
   "source": [
    "This will convert the train set into a list of `dsp.Example` instances to use for demonstrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a145a809-6cc7-4711-aa94-850fd1383ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_recogs_train = [dsp.Example(input=row['input'], output=row['output'])\n",
    "                    for _, row in dataset['train'].iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac35f2a-9b07-4b0c-bab4-1e4e022f5b03",
   "metadata": {},
   "source": [
    "### Basic template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7860e77a-5799-4975-9b6a-50373aeb743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = dsp.Type(\n",
    "    prefix=\"Input:\", \n",
    "    desc=\"${the sentence to be translated}\")\n",
    "\n",
    "Output = dsp.Type(\n",
    "    prefix=\"Output:\", \n",
    "    desc=\"${a logical form}\",\n",
    "    format=dsp.format_answers)\n",
    "\n",
    "cogs_template = dsp.Template(\n",
    "    instructions=\"Translate sentences into logical forms.\",\n",
    "    input=Input(),\n",
    "    output=Output())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ff4b52-fa07-4ea8-96c7-bfa91303ebf9",
   "metadata": {},
   "source": [
    "Quick illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "00d130f3-55f6-4e50-875d-bac368405ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate sentences into logical forms.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Input: ${the sentence to be translated}\n",
      "Output: ${a logical form}\n",
      "\n",
      "---\n",
      "\n",
      "Input: The resident was handed the cake beside a computer .\n",
      "Output: * resident ( 1 ) ; * cake ( 5 ) ; computer ( 8 ) ; hand ( 3 ) AND recipient ( 3 , 1 ) AND theme ( 3 , 5 ) AND nmod . beside ( 5 , 8 )\n",
      "\n",
      "---\n",
      "\n",
      "Input: The cake was frozen by the baby .\n",
      "Output: * cake ( 1 ) ; * baby ( 6 ) ; freeze ( 3 ) AND theme ( 3 , 1 ) AND agent ( 3 , 6 )\n",
      "\n",
      "---\n",
      "\n",
      "Input: A rose was helped by a dog .\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "ex = dsp.Example(\n",
    "    input=dataset['train'].input[0],\n",
    "    demos=dsp.sample(dsp_recogs_train, k=2))\n",
    "\n",
    "\n",
    "result = cogs_template(ex)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa596d1b-61ed-4c5d-b3af-dceb1c0861f8",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c27587-4c06-453d-9579-6429a762df8e",
   "metadata": {},
   "source": [
    "Your task is just to complete the following very basic DSP program. The steps are laid out for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "11a45b47-e2ab-4a5d-a0b3-b5507c4d4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def recogs_dsp(example, train=dsp_recogs_train, k=2): \n",
    "    pass\n",
    "    # Step 1: Sample k train cases and add them to the `demos`\n",
    "    # attribute of `example`:\n",
    "    ##### YOUR CODE HERE\n",
    "    example.demos = dsp.sample(train, k=k)\n",
    "\n",
    "\n",
    "\n",
    "    # Run your program using `cogs_template`:\n",
    "    ##### YOUR CODE HERE\n",
    "    # states_ex, states_compl = dsp.generate(cogs_template)(example, stage='basics')\n",
    "    states_compl = None\n",
    "\n",
    "\n",
    "\n",
    "    # Return the `dsp.Completions`:\n",
    "    ##### YOUR CODE HERE\n",
    "    return states_compl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82299806-3fe7-4b96-ba74-f1a4624c4654",
   "metadata": {},
   "source": [
    "A quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e4dc1175-8a2d-4de4-a71c-1abb61d78f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recogs_dsp(func):\n",
    "    k = 3\n",
    "    ex = dsp.Example(input=\"Q0\", output=[\"A0\"])\n",
    "    train = [\n",
    "        dsp.Example(input=\"Q1\", output=[\"A1\"]),\n",
    "        dsp.Example(input=\"Q2\", output=[\"A2\"]),\n",
    "        dsp.Example(input=\"Q3\", output=[\"A3\"]),\n",
    "        dsp.Example(input=\"Q4\", output=[\"A4\"])]\n",
    "    compl = func(ex, train=train, k=k)\n",
    "    errcount = 0\n",
    "    # Check the LM was used as expected:\n",
    "    if len(compl.data) != 1:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: Unexpected LM output.\")\n",
    "    data = compl.data[0]\n",
    "    # Check that the right number of demos was used:\n",
    "    demos = data['demos']\n",
    "    if len(demos) != k:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "              f\"Unexpected demo count: {len(demos)}\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors found for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4ab096a5-a7ee-4fd0-941a-7f70c403f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_recogs_dsp(recogs_dsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b3cf46aa-3881-4a3d-8592-7c5292786f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recogs_dsp(ex).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaa937-771e-4202-88a7-c6e708a3d3ad",
   "metadata": {},
   "source": [
    "### Optional assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca366b-aa51-4d81-b400-c6c9500eb482",
   "metadata": {},
   "source": [
    "Here we sample 10 dev cases for a small evaluation. If you adapt this code, remember to use `recogs_exact_match` so that you aren't unfairly penalized for conjunct order or varible name differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6a20ae08-86ef-40da-a963-69a7333647ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssamp = dataset['dev'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "268a2271-8a65-4355-8885-6f2bc214ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssamp['prediction'] = ssamp.input.apply(\n",
    "#     lambda x: recogs_dsp(dsp.Example(input=x)).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d9415ce6-a4e2-4b03-81dd-5ad85e0de78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssamp['correct'] = ssamp.apply(\n",
    "#     lambda row: recogs_exact_match(row['output'], row['prediction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "aa9e743e-5941-47dd-8953-cc3b302a314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssamp['correct'].sum() / ssamp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294287-5808-4eb7-ac2d-19bd0b660bd2",
   "metadata": {},
   "source": [
    "A random example to see what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "909fa032-f559-4971-94a8-16c7eba054d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'The pancake was liked .',\n",
       "  'output': '* pancake ( 32 ) ; like ( 26 ) AND theme ( 26 , 32 )',\n",
       "  'category': 'in_distribution'},\n",
       " {'input': 'The chalk was awarded to the penguin by Emma .',\n",
       "  'output': '* chalk ( 7 ) ; * penguin ( 56 ) ; Emma ( 25 ) ; award ( 26 ) AND theme ( 26 , 7 ) AND recipient ( 26 , 56 ) AND agent ( 26 , 25 )',\n",
       "  'category': 'in_distribution'},\n",
       " {'input': 'A butterfly rolled a jigsaw beside a stage .',\n",
       "  'output': 'butterfly ( 1 ) ; jigsaw ( 45 ) ; stage ( 11 ) ; nmod . beside ( 45 , 11 ) AND roll ( 59 ) AND agent ( 59 , 1 ) AND theme ( 59 , 45 )',\n",
       "  'category': 'in_distribution'},\n",
       " {'input': 'The teacher liked a boy .',\n",
       "  'output': '* teacher ( 2 ) ; boy ( 6 ) ; like ( 22 ) AND agent ( 22 , 2 ) AND theme ( 22 , 6 )',\n",
       "  'category': 'in_distribution'},\n",
       " {'input': 'Logan forwarded the girl the cake beside the stage .',\n",
       "  'output': 'Logan ( 16 ) ; * girl ( 47 ) ; * cake ( 34 ) ; * stage ( 1 ) ; nmod . beside ( 34 , 1 ) AND forward ( 12 ) AND agent ( 12 , 16 ) AND recipient ( 12 , 47 ) AND theme ( 12 , 34 )',\n",
       "  'category': 'in_distribution'}]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssamp.sample(5).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf84b5-af29-4a55-8f83-6f71fdb1c054",
   "metadata": {},
   "source": [
    "## Question 4: Original System [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa81ab-c4a1-4f4e-9d50-d223f81c90a6",
   "metadata": {},
   "source": [
    "For your original system, you can do anything at all. The only constraint (repeated from above):\n",
    "\n",
    "__You cannot train your system on any examples from `dataset[\"gen\"]`, nor can the output representations from those examples be included in any prompts used for in-context learning.__\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b9b50392-e869-4315-bb2f-09b76b8000ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "\n",
    "# To utilize the power of the pre-trained model, I will furthur train the ReCOGS model \n",
    "\n",
    "\n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb4dab-c0a9-4b1c-a556-148d66b2a77a",
   "metadata": {},
   "source": [
    "Here are some potential paths – just a few of many options, though!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20adf07-b7f3-4e6f-b172-73cfe781b7a4",
   "metadata": {},
   "source": [
    "### Option: DSP program\n",
    "\n",
    "This could build on Question 3 very directly. All we have tried ourselves so far is the simple approach from that question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da281ffa-ecf4-4598-bd1f-484153378a18",
   "metadata": {},
   "source": [
    "### Option: Further training of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb6de7-bab8-4f38-9567-49ea8d47dda7",
   "metadata": {},
   "source": [
    "This is very easy to do. For example, here we do some training on the first 10 dev examples, and we've exposed some keyword arguments that may be of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "76cf1b21-8059-4bc2-9cf8-a23b910e8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recogs_ff = RecogsModel(\n",
    "    batch_size=32,\n",
    "    gradient_accumulation_steps=20,\n",
    "    max_iter=300, \n",
    "    early_stopping=False,\n",
    "    n_iter_no_change=100,\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    eta=1e-4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = pd.concat((dataset['dev'], dataset['test']))\n",
    "ds = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2bd269d1-d835-4241-a5b6-0463883a42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = recogs_ff.fit(ds.input, ds.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af5ee4-d7e9-4700-8700-0021f11a1e1a",
   "metadata": {},
   "source": [
    "For this, you will want to pay a lot of attention to the optimization-related parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(valid_df, model):\n",
    "    struct_cats = [\n",
    "        \"obj_pp_to_subj_pp\",\n",
    "        \"cp_recursion\",\n",
    "        \"pp_recursion\",\n",
    "        \"subj_to_obj_proper\",\n",
    "        \"prim_to_obj_proper\",\n",
    "        \"prim_to_subj_proper\",\n",
    "    ]\n",
    "    dfs = [category_assess(valid_df, model, cat) for cat in struct_cats]\n",
    "    df = pd.concat(dfs)\n",
    "    result = [get_accuracy(d) for d in dfs]\n",
    "    result = dict(zip(struct_cats, result))\n",
    "    lex_dfs = pd.concat([\n",
    "        category_assess(valid_df, model, cat)\n",
    "        for cat in valid_df.category.unique()\n",
    "        if cat not in struct_cats\n",
    "    ])\n",
    "    result[\"LEX\"] = get_accuracy(lex_dfs)\n",
    "    df = pd.concat([df, lex_dfs])\n",
    "    result[\"OVERALL\"] = get_accuracy(df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ds = dataset['gen'].sample(1000, random_state=42)\n",
    "valid_df = dataset['gen'][: 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344077"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of model params\n",
    "sum(p.numel() for p in recogs_ff.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_pp_to_subj_pp': 0.0,\n",
       " 'cp_recursion': 6.896551724137931,\n",
       " 'pp_recursion': 0.0,\n",
       " 'subj_to_obj_proper': 90.9090909090909,\n",
       " 'prim_to_obj_proper': 43.90243902439025,\n",
       " 'prim_to_subj_proper': 90.38461538461539,\n",
       " 'LEX': 64.58036984352773,\n",
       " 'OVERALL': 56.3}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(valid_df, recogs_ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original: 0.559  \n",
    "pp_dative_to_do_dative 0.15384615384615385  \n",
    "passive_to_active 0.06666666666666667  \n",
    "obj_pp_to_subj_pp 0.0  \n",
    "cp_recursion 0.029411764705882353  \n",
    "obj_omitted_transitive_to_transitive 0.34615384615384615  \n",
    "prim_to_obj_proper 0.4827586206896552  \n",
    "pp_recursion 0.0  \n",
    "prim_to_subj_proper 0.8653846153846154  \n",
    "only_seen_as_unacc_subj_as_obj_omitted_transitive_subj 0.9056603773584906  \n",
    "unacc_to_transitive 0.6346153846153846  \n",
    "prim_to_obj_common 0.6410256410256411  \n",
    "subj_to_obj_common 0.7555555555555555  \n",
    "obj_to_subj_proper 0.9069767441860465  \n",
    "obj_to_subj_common 0.9534883720930233  \n",
    "subj_to_obj_proper 0.8297872340425532  \n",
    "only_seen_as_unacc_subj_as_unerg_subj 0.9583333333333334  \n",
    "prim_to_inf_arg 0.0  \n",
    "do_dative_to_pp_dative 0.7407407407407407  \n",
    "active_to_passive 1.0  \n",
    "only_seen_as_transitive_subj_as_unacc_subj 0.9285714285714286  \n",
    "prim_to_subj_common 0.5454545454545454  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzanqi-liang\u001b[0m (\u001b[33mbigz\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=recogs_sweeps\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "%env WANDB_PROJECT=recogs_sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "        'value': 1\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'values': [8, 16, 32, 64]\n",
    "        },\n",
    "    'gradient_accumulation_steps': {\n",
    "        'values': [1, 2, 4, 8, 20, 40]\n",
    "        },\n",
    "    'n_iter_no_change': {\n",
    "        'values': [2, 5, 10, 20]\n",
    "        },\n",
    "    'optimizer_class': {\n",
    "        'values': ['Adam', 'AdamW']\n",
    "        },\n",
    "    'eta': {\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-6,\n",
    "        'max': 1e-4\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "# sweep_id = wandb.sweep(sweep_config, project='recogs-sweeps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        recogs_ff = RecogsModel(\n",
    "            batch_size=config.batch_size,\n",
    "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "            max_iter=100, \n",
    "            early_stopping=False,\n",
    "            # n_iter_no_change=config.n_iter_no_change,\n",
    "            optimizer_class=torch.optim.Adam if config.optimizer_class == 'Adam' else torch.optim.AdamW,\n",
    "            eta=config.eta)\n",
    "        \n",
    "        _ = recogs_ff.fit(dataset['dev'].input[: 400], dataset['dev'].output[: 400])\n",
    "    \n",
    "        dfs = [category_assess(valid_df, recogs_ff, c) for c in valid_df.category.unique()]\n",
    "        df = pd.concat(dfs)\n",
    "    \n",
    "        wandb.log({'accuracy': get_accuracy(df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.agent(sweep_id, train, count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64ec5e-56dd-4174-96ea-b9574a39ea58",
   "metadata": {},
   "source": [
    "### Option: Using a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f245a-c474-4723-a1c8-ea4666c22ce5",
   "metadata": {},
   "source": [
    "The code used for Question 2 should make this very easy. For example, the following is the start of a complete solution using T5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d75cf2f9-bedc-48e6-a367-747008002eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "class T5RecogsModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encdec = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "    def forward(self, X_pad, X_mask, y_pad, y_mask, labels=None):\n",
    "        outputs = self.encdec(\n",
    "            input_ids=X_pad, \n",
    "            attention_mask=X_mask,\n",
    "            decoder_attention_mask=y_mask,\n",
    "            labels=y_pad)\n",
    "        return outputs\n",
    "\n",
    "class T5RecogsModel(RecogsModel):\n",
    "    def __init__(self, *args, initialize=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.enc_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        self.dec_tokenizer = self.enc_tokenizer\n",
    "\n",
    "    def build_graph(self):\n",
    "        return T5RecogsModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ca475-f788-441a-a32e-f3feed6aa88b",
   "metadata": {},
   "source": [
    "This will make predictions, but they will be pretty totally disconnected from our task right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "eded1da8-e9ba-4cf8-a5ef-6d6c7c41ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5mod = T5RecogsModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b9074288-99ea-41d8-8430-7a6887957953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Liam hoped that a box was burned by a girl .\n",
       "1      The donkey lended the cookie to a mother .\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_exs = dataset['dev'].input[: 2]\n",
    "\n",
    "t5_exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0a683db7-38de-49b0-b2d2-92cebeb1daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liam hoffte, dass eine Box von einer Frau in der Hand gelegt wird.',\n",
       " 'Der Donkey lended den Cookie an eine Mutter .']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5mod.predict(t5_exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5mod = RecogsModel(\n",
    "    batch_size=32,\n",
    "    gradient_accumulation_steps=20,\n",
    "    max_iter=10, \n",
    "    early_stopping=False,\n",
    "    n_iter_no_change=100,\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    eta=1e-5,)\n",
    "\n",
    "# t5mod.fit(ds.input, ds.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb Cell 173\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m acc, pred \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m(valid_df, t5mod)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(acc)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m valid_df\u001b[39m.\u001b[39mcategory\u001b[39m.\u001b[39munique():\n",
      "\u001b[1;32m/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb Cell 173\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m result \u001b[39m=\u001b[39m [get_accuracy(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dfs]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(struct_cats, result))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m lex_dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     category_assess(valid_df, model, cat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m cat \u001b[39min\u001b[39;49;00m valid_df\u001b[39m.\u001b[39;49mcategory\u001b[39m.\u001b[39;49munique()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m cat \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m struct_cats\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mLEX\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m get_accuracy(lex_dfs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, lex_dfs])\n",
      "\u001b[1;32m/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb Cell 173\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m result \u001b[39m=\u001b[39m [get_accuracy(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dfs]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(struct_cats, result))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m lex_dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     category_assess(valid_df, model, cat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m valid_df\u001b[39m.\u001b[39mcategory\u001b[39m.\u001b[39munique()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m cat \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m struct_cats\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mLEX\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m get_accuracy(lex_dfs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, lex_dfs])\n",
      "\u001b[1;32m/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb Cell 173\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m cat_df \u001b[39m=\u001b[39m gen_df[gen_df\u001b[39m.\u001b[39mcategory \u001b[39m==\u001b[39m category]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Step 1: Add a column called \"prediction\" to `cat_df`. This should\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# give the predicted LFs:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m##### YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m cat_df[\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(cat_df\u001b[39m.\u001b[39;49minput)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Step 2: Add a column \"correct\" that says whether the prediction\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# and the gold output are the same. Must use `recogs_exact_match`.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m##### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m cat_df[\u001b[39m\"\u001b[39m\u001b[39mcorrect\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [recogs_exact_match(gold, pred) \u001b[39mfor\u001b[39;00m gold, pred \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(cat_df\u001b[39m.\u001b[39moutput, cat_df\u001b[39m.\u001b[39mprediction)]\n",
      "\u001b[1;32m/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb Cell 173\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     X_pad, X_mask \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencdec\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         X_pad,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mX_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencdec\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49meos_token_id)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdec_tokenizer\u001b[39m.\u001b[39mbatch_decode(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         outputs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         clean_up_tokenization_spaces\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zanqiliang/Documents/cs224u/hw_recogs.ipynb#Y333sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     preds \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m results\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/generation/utils.py:1522\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1517\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m         )\n\u001b[1;32m   1521\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1522\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1523\u001b[0m         input_ids,\n\u001b[1;32m   1524\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1525\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1526\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1527\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1528\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1529\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1530\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1531\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1532\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1533\u001b[0m     )\n\u001b[1;32m   1535\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1536\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/generation/utils.py:2339\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2338\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2340\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2341\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2342\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2343\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2344\u001b[0m )\n\u001b[1;32m   2346\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2347\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:625\u001b[0m, in \u001b[0;36mEncoderDecoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m     decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m    621\u001b[0m         labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    624\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m    626\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m    627\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m    628\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    629\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    630\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m    631\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    632\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    633\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    634\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    635\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    636\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_decoder,\n\u001b[1;32m    637\u001b[0m )\n\u001b[1;32m    639\u001b[0m \u001b[39m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[39;00m\n\u001b[1;32m    640\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1234\u001b[0m, in \u001b[0;36mBertLMHeadModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1235\u001b[0m     input_ids,\n\u001b[1;32m   1236\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1237\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1238\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1239\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1240\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1241\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1242\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1243\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1244\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1245\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1246\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1247\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[1;32m   1250\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1251\u001b[0m prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:230\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    227\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[1;32m    231\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    233\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc, pred = eval(valid_df, t5mod)\n",
    "print(acc)\n",
    "\n",
    "for c in valid_df.category.unique():\n",
    "    print(c, get_accuracy(pred[pred.category == c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1\n",
    "# 0.466\n",
    "# pp_dative_to_do_dative 0.038461538461538464\n",
    "# passive_to_active 0.0\n",
    "# obj_pp_to_subj_pp 0.0\n",
    "# cp_recursion 0.029411764705882353\n",
    "# obj_omitted_transitive_to_transitive 0.038461538461538464\n",
    "# prim_to_obj_proper 0.5517241379310345\n",
    "# pp_recursion 0.0\n",
    "# prim_to_subj_proper 0.8269230769230769\n",
    "# only_seen_as_unacc_subj_as_obj_omitted_transitive_subj 0.8113207547169812\n",
    "# unacc_to_transitive 0.38461538461538464\n",
    "# prim_to_obj_common 0.717948717948718\n",
    "# subj_to_obj_common 0.7111111111111111\n",
    "# obj_to_subj_proper 0.7906976744186046\n",
    "# obj_to_subj_common 0.813953488372093\n",
    "# subj_to_obj_proper 0.7872340425531915\n",
    "# only_seen_as_unacc_subj_as_unerg_subj 0.7291666666666666\n",
    "# prim_to_inf_arg 0.0\n",
    "# do_dative_to_pp_dative 0.5740740740740741\n",
    "# active_to_passive 0.8095238095238095\n",
    "# only_seen_as_transitive_subj_as_unacc_subj 0.7380952380952381\n",
    "# prim_to_subj_common 0.4727272727272727\n",
    "\n",
    "# V2\n",
    "# 0.381\n",
    "# pp_dative_to_do_dative 0.09615384615384616\n",
    "# passive_to_active 0.0\n",
    "# obj_pp_to_subj_pp 0.0\n",
    "# cp_recursion 0.0\n",
    "# obj_omitted_transitive_to_transitive 0.019230769230769232\n",
    "# prim_to_obj_proper 0.4482758620689655\n",
    "# pp_recursion 0.0\n",
    "# prim_to_subj_proper 0.46153846153846156\n",
    "# only_seen_as_unacc_subj_as_obj_omitted_transitive_subj 0.8490566037735849\n",
    "# unacc_to_transitive 0.3269230769230769\n",
    "# prim_to_obj_common 0.3333333333333333\n",
    "# subj_to_obj_common 0.37777777777777777\n",
    "# obj_to_subj_proper 0.5116279069767442\n",
    "# obj_to_subj_common 0.627906976744186\n",
    "# subj_to_obj_proper 0.7872340425531915\n",
    "# only_seen_as_unacc_subj_as_unerg_subj 0.6875\n",
    "# prim_to_inf_arg 0.0\n",
    "# do_dative_to_pp_dative 0.7222222222222222\n",
    "# active_to_passive 0.6904761904761905\n",
    "# only_seen_as_transitive_subj_as_unacc_subj 0.7142857142857143\n",
    "# prim_to_subj_common 0.2909090909090909"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21f911-69d3-4fa1-b3eb-6c73b494a15c",
   "metadata": {},
   "source": [
    "This model needs to be fine-tuned on ReCOGS, which you can do with its `fit` method. In that case, you will want to pay a lot of attention to the optimization-related parameters to `TorchModelBase`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15c129-8ada-4114-9c59-42ebc8025b59",
   "metadata": {},
   "source": [
    "### Option: Training a seq2seq model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e69f3-a5dd-4288-8d6c-ae652dac6365",
   "metadata": {},
   "source": [
    "The above code for T5 is easily adapted to use a randomly initialized model. The config files used to train our core model are `encoder_config.json` and `decoder_config.json` in `SRC_DIRNAME`. These might be a good starting point in terms of parameters and other set-up details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ee76-5119-4e89-ac12-42d2933bb2b0",
   "metadata": {},
   "source": [
    "### There are lots more options!\n",
    "\n",
    "Maybe a symbolic solver? A learned semantic parser? Tree-structured neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521ebabe-bfa7-4559-b7a6-e677b9241815",
   "metadata": {},
   "source": [
    "## Question 5: Bakeoff entry [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab31552-ed3c-41cc-b187-d45ec408a3ba",
   "metadata": {},
   "source": [
    "Here we read in the bakeoff dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f943f3-de8c-4f0c-924e-8c705be013b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeoff_df = pd.read_csv(\n",
    "    os.path.join(SRC_DIRNAME, \"cs224u-recogs-test-unlabeled.tsv\"), \n",
    "    sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b8d2c-169e-4fd5-a4d6-004d70b0b0d2",
   "metadata": {},
   "source": [
    "For the bakeoff entry, you should add a column \"prediction\" containing your predicted LFs and then use the following command to write the file to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3120b-a736-464a-a387-9a3bdc9bdcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeoff_df.to_csv(\"cs224u-recogs-bakeoff-entry.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bac05-b45d-4f0b-9ad8-e52b83b9760f",
   "metadata": {},
   "source": [
    "Here is what the first couple of lines of the file should look like:\n",
    "\n",
    "```\n",
    "\tinput\tcategory\tprediction\n",
    "0\tA cake was blessed by the wolf .\tactive_to_passive\tPREDICTED LF\n",
    "1\tA melon was blessed by a boy .\tactive_to_passive\tPREDICTED LF\n",
    "```\n",
    "\n",
    "where `PREDICTED LF` is what you predicted. Here is a quick test you can run locally to ensure that the autograder won't fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5eec46-2508-4818-a9ff-1989f99bfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bakeoff_file(filename=\"cs224u-recogs-bakeoff-entry.tsv\"):\n",
    "    ref_filename = os.path.join(SRC_DIRNAME, \"cs224u-recogs-test-unlabeled.tsv\")\n",
    "    ref_df = pd.read_csv(ref_filename, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    entry_df = pd.read_csv(filename, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    errcount = 0\n",
    "\n",
    "    # Check expected columns:\n",
    "    expected_cols = [\"input\", \"category\", \"prediction\"]\n",
    "    for col in expected_cols:\n",
    "        if col not in entry_df.columns:\n",
    "            errcount += 1\n",
    "            print(f\"Missing column: {col}\")\n",
    "    if errcount > 0:\n",
    "        return\n",
    "\n",
    "    # Use the \"category\" column as a check that the rows have not\n",
    "    # been shuffled:\n",
    "    if not entry_df.category.equals(ref_df.category):\n",
    "        errcount += 1\n",
    "        print(\"Rows do not seem to be aligned with reference file. \"\n",
    "              \"Might they have gotten shuffled?\")\n",
    "\n",
    "    # Check that the predictions all have type str:\n",
    "    for line_num, x in enumerate(entry_df.prediction, start=1):\n",
    "        if not isinstance(x, str):\n",
    "            errcount += 1\n",
    "            print(f\"Prediction on line {line_num} is not a str: {x}\")\n",
    "\n",
    "    if errcount == 0:\n",
    "        print(\"Bakeoff file seems to be in good shape!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d37fe9-6014-4fac-b9d6-5552a01ce72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing column: prediction\n"
     ]
    }
   ],
   "source": [
    "test_bakeoff_file(\"cs224u-recogs-bakeoff-entry.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
