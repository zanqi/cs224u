{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: Word relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [Development dataset](#Development-dataset)\n",
    "    1. [Vocabulary](#Vocabulary)\n",
    "    1. [Score distribution](#Score-distribution)\n",
    "    1. [Repeated pairs](#Repeated-pairs)\n",
    "1. [Evaluation](#Evaluation)\n",
    "1. [Error analysis](#Error-analysis)\n",
    "1. [Homework questions](#Homework-questions)\n",
    "    1. [PPMI as a baseline [0.5 points]](#PPMI-as-a-baseline-[0.5-points])\n",
    "    1. [Gigaword with LSA at different dimensions [0.5 points]](#Gigaword-with-LSA-at-different-dimensions-[0.5-points])\n",
    "    1. [t-test reweighting [2 points]](#t-test-reweighting-[2-points])\n",
    "    1. [Pooled BERT representations [1 point]](#Pooled-BERT-representations-[1-point])\n",
    "    1. [Learned distance functions [2 points]](#Learned-distance-functions-[2-points])\n",
    "    1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bake-off [1 point]](#Bake-off-[1-point])\n",
    "1. [Submission instructions](#Submission-instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Word similarity and relatedness datasets have long been used to evaluate distributed representations. This notebook provides code for conducting such analyses with a new word relatedness datasets. It consists of word pairs, each with an associated human-annotated relatedness score. \n",
    "\n",
    "The evaluation metric for each dataset is the [Spearman correlation coefficient $\\rho$](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) between the annotated scores and your distances, as is standard in the literature.\n",
    "\n",
    "This homework ([questions at the bottom of this notebook](#Homework-questions)) asks you to write code that uses the count matrices in `data/vsmdata` to create and evaluate some baseline models. The final question asks you to create your own original system for this task, using any data you wish. This accounts for 9 of the 10 points for this assignment.\n",
    "\n",
    "For the associated bake-off, we will distribute a new dataset, and you will evaluate your original system (no additional training or tuning allowed!) on that datasets and submit your predictions. Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import vsm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VSM_HOME = os.path.join('data', 'vsmdata')\n",
    "\n",
    "DATA_HOME = os.path.join('data', 'wordrelatedness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use development dataset freely, since our bake-off evalutions involve a new test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(\n",
    "    os.path.join(DATA_HOME, \"cs224u-wordrelatedness-dev.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of word pairs with scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>button</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>consigning</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>crane</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>ditch</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandon</td>\n",
       "      <td>left</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1       word2  score\n",
       "0  abandon      button   0.18\n",
       "1  abandon  consigning   0.40\n",
       "2  abandon       crane   0.16\n",
       "3  abandon       ditch   0.63\n",
       "4  abandon        left   0.57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the number of word pairs in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4756"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set will contain 1500 word pairs with scores of the same type. No word pair in the development set appears in the test set, but some of the individual words are repeated in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full vocabulary in the dataframe can be extracted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_vocab = set(dev_df.word1.values) | set(dev_df.word2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2809"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary for the bake-off test is different â€“ it is partly overlapping with the above. If you want to be sure ahead of time that your system has a representation for every word in the dev and test sets, then you can check against the vocabularies of any of the VSMs in `data/vsmdata` (which all have the same vocabulary). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_index = pd.read_csv(\n",
    "    os.path.join(VSM_HOME, 'yelp_window5-scaled.csv.gz'),\n",
    "    usecols=[0], index_col=0)\n",
    "\n",
    "full_task_vocab = list(task_index.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_task_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can process every one of those words, then you are all set. Alternatively, you can wait to see the test set and make system adjustments to ensure that you can process all those words. This is fine as long as you are not tuning your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the scores fall in $[0, 1]$, and the dataset skews towards words with low scores, meaning low relatedness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = dev_df.plot.hist().set_xlabel(\"Relatedness score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development data has some word pairs with multiple distinct scores in it. Here we create a `pd.Series` that contains these word pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = dev_df.groupby(['word1', 'word2']).apply(lambda x: x.score.var())\n",
    "\n",
    "repeats = repeats[repeats > 0].sort_values(ascending=False)\n",
    "\n",
    "repeats.name = 'score variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeats.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pd.Series` is sorted with the highest variance items at the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word1    word2     \n",
       "buck     dollar        0.378592\n",
       "furnace  stove         0.274653\n",
       "cash     money         0.247104\n",
       "boxing   round         0.189342\n",
       "money    possession    0.187652\n",
       "Name: score variance, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is development data, it is up to you how you want to handle these repeats. The test set has no repeated pairs in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation function is `vsm.word_relatedness_evaluation`. Its arguments:\n",
    "    \n",
    "1. A relatedness dataset `pd.DataFrame` â€“ e.g., `dev_df` as given above.\n",
    "1. A VSM `pd.DataFrame` â€“ e.g., `giga5` or some transformation thereof, or a GloVe embedding space, or something you have created on your own. The function checks that you can supply a representation for every word in `dev_df` and raises an exception if you can't.\n",
    "1. Optionally a `distfunc` argument, which defaults to `vsm.cosine`.\n",
    "\n",
    "The function returns a tuple:\n",
    "\n",
    "1. A copy of `dev_df` with a new column giving your predictions.\n",
    "1. The Spearman $\\rho$ value (our primary score).\n",
    "\n",
    "Important note: Internally, `vsm.word_relatedness_evaluation` uses `-distfunc(x1, x2)` as its score, where `x1` and `x2` are vector representations of words. This is because the scores in our data are _positive_ relatedness scores, whereas we are assuming that `distfunc` is a _distance_ function.\n",
    "\n",
    "Here's a simple illustration using one of our count matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.read_csv(\n",
    "    os.path.join(VSM_HOME, \"giga_window5-scaled.csv.gz\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pred_df, count_rho = vsm.word_relatedness_evaluation(dev_df, count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2776320615138188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>button</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.336291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>consigning</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.085422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>crane</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.307229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>ditch</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.211550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandon</td>\n",
       "      <td>left</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.337866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1       word2  score  prediction\n",
       "0  abandon      button   0.18   -0.336291\n",
       "1  abandon  consigning   0.40   -0.085422\n",
       "2  abandon       crane   0.16   -0.307229\n",
       "3  abandon       ditch   0.63   -0.211550\n",
       "4  abandon        left   0.57   -0.337866"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's instructive to compare this against a truly random system, which we can create by simply having a custom distance function that returns a random number in [0, 1] for each example, making no use of the VSM itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scorer(x1, x2):\n",
    "    \"\"\"`x1` and `x2` are vectors, to conform to the requirements\n",
    "    of `vsm.word_relatedness_evaluation`, but this function just\n",
    "    returns a random number in [0, 1].\"\"\"\n",
    "    return random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00059854523902375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred_df, random_rho = vsm.word_relatedness_evaluation(\n",
    "    dev_df, count_df, distfunc=random_scorer)\n",
    "\n",
    "random_rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a truly baseline system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "For error analysis, we can look at the words with the largest delta between the gold score and the distance value in our VSM. We do these comparisons based on ranks, just as with our primary metric (Spearman $\\rho$), and we normalize both rankings so that they have a comparable number of levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(pred_df):\n",
    "    pred_df = pred_df.copy()\n",
    "    pred_df['relatedness_rank'] = _normalized_ranking(pred_df.prediction)\n",
    "    pred_df['score_rank'] = _normalized_ranking(pred_df.score)\n",
    "    pred_df['error'] =  abs(pred_df['relatedness_rank'] - pred_df['score_rank'])\n",
    "    return pred_df.sort_values('error')\n",
    "\n",
    "\n",
    "def _normalized_ranking(series):\n",
    "    ranks = series.rank(method='dense')\n",
    "    return ranks / ranks.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>relatedness_rank</th>\n",
       "      <th>score_rank</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>health</td>\n",
       "      <td>psychology</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>-0.238147</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>3.284913e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>grey</td>\n",
       "      <td>purple</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>-0.125642</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>3.895284e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>eye</td>\n",
       "      <td>organ</td>\n",
       "      <td>0.789141</td>\n",
       "      <td>-0.073605</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>6.168281e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>losses</td>\n",
       "      <td>play</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>-0.163590</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>1.214181e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>appearance</td>\n",
       "      <td>image</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>-0.166412</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1.518298e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word1       word2     score  prediction  relatedness_rank  \\\n",
       "3121      health  psychology  0.325000   -0.238147          0.000127   \n",
       "2984        grey      purple  0.660000   -0.125642          0.000283   \n",
       "2439         eye       organ  0.789141   -0.073605          0.000361   \n",
       "3591      losses        play  0.543103   -0.163590          0.000223   \n",
       "239   appearance       image  0.535000   -0.166412          0.000218   \n",
       "\n",
       "      score_rank         error  \n",
       "3121    0.000127  3.284913e-08  \n",
       "2984    0.000283  3.895284e-08  \n",
       "2439    0.000361  6.168281e-08  \n",
       "3591    0.000222  1.214181e-07  \n",
       "239     0.000218  1.518298e-07  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis(count_pred_df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>relatedness_rank</th>\n",
       "      <th>score_rank</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>submit</td>\n",
       "      <td>yield</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>-0.473501</td>\n",
       "      <td>1.440789e-05</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>bulletin</td>\n",
       "      <td>news</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>-0.503304</td>\n",
       "      <td>1.082946e-05</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>photo</td>\n",
       "      <td>picture</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>-0.632888</td>\n",
       "      <td>2.165892e-06</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>grow</td>\n",
       "      <td>sprouting</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>-0.518391</td>\n",
       "      <td>9.134414e-06</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>repeating</td>\n",
       "      <td>replicate</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>-0.728052</td>\n",
       "      <td>3.766768e-07</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word1      word2     score  prediction  relatedness_rank  \\\n",
       "4643     submit      yield  0.916750   -0.473501      1.440789e-05   \n",
       "1010   bulletin       news  0.925926   -0.503304      1.082946e-05   \n",
       "4091      photo    picture  0.920000   -0.632888      2.165892e-06   \n",
       "3001       grow  sprouting  0.950000   -0.518391      9.134414e-06   \n",
       "4338  repeating  replicate  0.925000   -0.728052      3.766768e-07   \n",
       "\n",
       "      score_rank     error  \n",
       "4643    0.000423  0.000408  \n",
       "1010    0.000425  0.000414  \n",
       "4091    0.000423  0.000421  \n",
       "3001    0.000430  0.000421  \n",
       "4338    0.000424  0.000424  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis(count_pred_df).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework questions\n",
    "\n",
    "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPMI as a baseline [0.5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insight behind PPMI is a recurring theme in word representation learning, so it is a natural baseline for our task. This question asks you to write code for conducting such experiments.\n",
    "\n",
    "Your task: write a function called `run_giga_ppmi_baseline` that does the following:\n",
    "\n",
    "1. Reads the Gigaword count matrix with a window of 20 and a flat scaling function into a `pd.DataFrame`, as is done in the VSM notebooks. The file is `data/vsmdata/giga_window20-flat.csv.gz`, and the VSM notebooks provide examples of the needed code.\n",
    "1. Reweights this count matrix with PPMI.\n",
    "1. Evaluates this reweighted matrix using `vsm.word_relatedness_evaluation` on `dev_df` as defined above, with `distfunc` set to the default of `vsm.cosine`.\n",
    "1. Returns the return value of this call to `vsm.word_relatedness_evaluation`.\n",
    "\n",
    "The goal of this question is to help you get more familiar with the code in `vsm` and the function `vsm.word_relatedness_evaluation`.\n",
    "\n",
    "The function `test_run_giga_ppmi_baseline` can be used to test that you've implemented this specification correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_giga_ppmi_baseline():\n",
    "    giga20 = pd.read_csv(\n",
    "        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0\n",
    "    )\n",
    "    giga20_ppmi = vsm.pmi(giga20)\n",
    "    return vsm.word_relatedness_evaluation(dev_df, giga20_ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_giga_ppmi_baseline(func):\n",
    "    \"\"\"`func` should be `run_giga_ppmi_baseline\"\"\"\n",
    "    pred_df, rho = func()\n",
    "    rho = round(rho, 3)\n",
    "    expected = 0.586\n",
    "    assert rho == expected, \\\n",
    "        \"Expected rho of {}; got {}\".format(expected, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_giga_ppmi_baseline(run_giga_ppmi_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gigaword with LSA at different dimensions [0.5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might expect PPMI and LSA to form a solid pipeline that combines the strengths of PPMI with those of dimensionality reduction. However, LSA has a hyper-parameter $k$ â€“ the dimensionality of the final representations â€“ that will impact performance. This problem asks you to create code that will help you explore this approach.\n",
    "\n",
    "Your task: write a wrapper function `run_ppmi_lsa_pipeline` that does the following:\n",
    "\n",
    "1. Takes as input a count `pd.DataFrame` and an LSA parameter `k`.\n",
    "1. Reweights the count matrix with PPMI.\n",
    "1. Applies LSA with dimensionality `k`.\n",
    "1. Evaluates this reweighted matrix using `vsm.word_relatedness_evaluation` with `dev_df` as defined above. The return value of `run_ppmi_lsa_pipeline` should be the return value of this call to `vsm.word_relatedness_evaluation`.\n",
    "\n",
    "The goal of this question is to help you get a feel for how LSA can contribute to this problem. \n",
    "\n",
    "The  function `test_run_ppmi_lsa_pipeline` will test your function on the count matrix in `data/vsmdata/giga_window20-flat.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ppmi_lsa_pipeline(count_df, k):\n",
    "    ppmi_df = vsm.pmi(count_df)\n",
    "    lsa_df = vsm.lsa(ppmi_df, k=k)\n",
    "    return vsm.word_relatedness_evaluation(dev_df, lsa_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_ppmi_lsa_pipeline(func):\n",
    "    \"\"\"`func` should be `run_ppmi_lsa_pipeline`\"\"\"\n",
    "    giga20 = pd.read_csv(\n",
    "        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n",
    "    pred_df, rho = func(giga20, k=10)\n",
    "    rho = round(rho, 3)\n",
    "    expected = 0.545\n",
    "    assert rho == expected,\\\n",
    "        \"Expected rho of {}; got {}\".format(expected, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_ppmi_lsa_pipeline(run_ppmi_lsa_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test reweighting [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test statistic can be thought of as a reweighting scheme. For a count matrix $X$, row index $i$, and column index $j$:\n",
    "\n",
    "$$\\textbf{ttest}(X, i, j) = \n",
    "\\frac{\n",
    "    P(X, i, j) - \\big(P(X, i, *)P(X, *, j)\\big)\n",
    "}{\n",
    "\\sqrt{(P(X, i, *)P(X, *, j))}\n",
    "}$$\n",
    "\n",
    "where $P(X, i, j)$ is $X_{ij}$ divided by the total values in $X$, $P(X, i, *)$ is the sum of the values in row $i$ of $X$ divided by the total values in $X$, and $P(X, *, j)$ is the sum of the values in column $j$ of $X$ divided by the total values in $X$.\n",
    "\n",
    "Your task: implement this reweighting scheme. You can use `test_ttest_implementation` below to check that your implementation is correct.  You do not need to use this for any evaluations, though we hope you will be curious enough to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(df):\n",
    "    col_totals = df.sum(axis=0)\n",
    "    row_totals = df.sum(axis=1)\n",
    "    total = col_totals.sum()\n",
    "    numerator = df - np.outer(row_totals, col_totals) / total\n",
    "    denom = np.sqrt(np.outer(row_totals, col_totals))\n",
    "    return numerator / denom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ttest_implementation(func):\n",
    "    \"\"\"`func` should be `ttest`\"\"\"\n",
    "    X = pd.DataFrame([\n",
    "        [1.,  4.,  3.,  0.],\n",
    "        [2., 43.,  7., 12.],\n",
    "        [5.,  6., 19.,  0.],\n",
    "        [1., 11.,  1.,  4.]])\n",
    "    actual = np.array([\n",
    "        [ 0.04655, -0.01337,  0.06346, -0.09507],\n",
    "        [-0.11835,  0.13406, -0.20846,  0.10609],\n",
    "        [ 0.16621, -0.23129,  0.38123, -0.18411],\n",
    "        [-0.0231 ,  0.0563 , -0.14549,  0.10394]])\n",
    "    predicted = func(X)\n",
    "    assert np.array_equal(predicted.round(5), actual), \\\n",
    "        \"Your ttest result is\\n{}\".format(predicted.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_ttest_implementation(ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_ttest(func):\n",
    "    \"\"\"`func` should be `ttest`\"\"\"\n",
    "    giga20 = pd.read_csv(\n",
    "        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n",
    "    ttest_df = func(giga20)\n",
    "    _pred, rho = vsm.word_relatedness_evaluation(dev_df, ttest_df)\n",
    "    rho = round(rho, 3)\n",
    "    expected = 0.593\n",
    "    assert rho == expected,\\\n",
    "        \"Expected rho of {}; got {}\".format(expected, rho)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run_ttest(ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on dev\n",
    "\n",
    "ppmi: 0.586 \\\n",
    "ppmi + lsa: 0.545 \\\n",
    "ttest: 0.585 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled BERT representations [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook [vsm_04_contextualreps.ipynb](vsm_04_contextualreps.ipynb) explores methods for deriving static vector representations of words from the contextual representations given by models like BERT and RoBERTa. The methods are due to [Bommasani et al. 2020](https://www.aclweb.org/anthology/2020.acl-main.431). The simplest of these methods involves processing the words as independent texts and pooling the sub-word representations that result, using a function like mean or max.\n",
    "\n",
    "Your task: write a function `evaluate_pooled_bert` that will enable exploration of this approach. The function should do the following:\n",
    "\n",
    "1. Take as its arguments (a) a word relatedness `pd.DataFrame` `rel_df` (e.g., `dev_df`), (b) a `layer` index (see below), and (c) a `pool_func` value (see below).\n",
    "1. Set up a BERT tokenizer and BERT model based on `'bert-base-uncased'`.\n",
    "1. Use `vsm.create_subword_pooling_vsm` to create a VSM (a `pd.DataFrame`) with the user's values for `layer` and `pool_func`.\n",
    "1. Return the return value of `vsm.word_relatedness_evaluation` using this new VSM, evaluated on `rel_df` with `distfunc` set to its default value.\n",
    "\n",
    "The function `vsm.create_subword_pooling_vsm` does the heavy-lifting. Your task is really just to put these pieces together. The result will be the start of a flexible framework for seeing how these methods do on our task. \n",
    "\n",
    "The function `test_evaluate_pooled_bert` can help you obtain the design we are seeking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "def evaluate_pooled_bert(rel_df, layer, pool_func):\n",
    "    bert_weights_name = 'bert-base-uncased'\n",
    "\n",
    "    # Initialize a BERT tokenizer and BERT model based on\n",
    "    # `bert_weights_name`:\n",
    "    ##### YOUR CODE HERE\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "    model = BertModel.from_pretrained(bert_weights_name)\n",
    "\n",
    "\n",
    "    # Get the vocabulary from `rel_df`:\n",
    "    ##### YOUR CODE HERE\n",
    "    vocab = list(set(rel_df.word1.values) | set(rel_df.word2.values))\n",
    "\n",
    "\n",
    "    # Use `vsm.create_subword_pooling_vsm` with the user's arguments:\n",
    "    ##### YOUR CODE HERE\n",
    "    bert_df = vsm.create_subword_pooling_vsm(\n",
    "        vocab, tokenizer, model, layer=layer, pool_func=pool_func)\n",
    "\n",
    "\n",
    "    # Return the results of the relatedness evalution:\n",
    "    ##### YOUR CODE HERE\n",
    "    return vsm.word_relatedness_evaluation(rel_df, bert_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate_pooled_bert(func):\n",
    "    import torch\n",
    "    rel_df = pd.DataFrame([\n",
    "        {'word1': 'porcupine', 'word2': 'capybara', 'score': 0.6},\n",
    "        {'word1': 'antelope', 'word2': 'springbok', 'score': 0.5},\n",
    "        {'word1': 'llama', 'word2': 'camel', 'score': 0.4},\n",
    "        {'word1': 'movie', 'word2': 'play', 'score': 0.3}])\n",
    "    layer = 2\n",
    "    pool_func = vsm.max_pooling\n",
    "    pred_df, rho = func(rel_df, layer, pool_func)\n",
    "    rho = round(rho, 2)\n",
    "    expected_rho = 0.40\n",
    "    assert rho == expected_rho, \\\n",
    "        \"Expected rho={}; got rho={}\".format(expected_rho, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_evaluate_pooled_bert(evaluate_pooled_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned distance functions [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presentation thus far leads one to assume that the `distfunc` argument used in the experiments will be a standard vector distance function like `vsm.cosine` or `vsm.euclidean`. However, the framework itself simply requires that this function map two fixed-dimensional vectors to a real number. This opens up a world of possibilities. This question asks you to dip a toe in these waters.\n",
    "\n",
    "Your task: write a function `run_knn_score_model` for models in this class. The function should:\n",
    "\n",
    "1. Take as its arguments (a) a VSM dataframe `vsm_df`, (b) a relatedness dataset (e.g., `dev_df`), and (c) a `test_size` value between 0.0 and 1.0 that can be passed directly to `train_test_split` (see below).\n",
    "1. Create a feature matrix `X`: each word pair in `dev_df` should be represented by the concatenation of the vectors for word1 and word2 from `vsm_df`.\n",
    "1. Create a score vector `y`, which is just the `score` column in `dev_df`.\n",
    "1. Split the dataset `(X, y)` into train and test portions using [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "1. Train an [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) model on the train split from step 4, with default hyperparameters.\n",
    "1. Return the value of the `score` method of the trained `KNeighborsRegressor` model on the test split from step 4.\n",
    "\n",
    "The functions `test_knn_feature_matrix` and `knn_represent` will help you test the crucial representational aspects of this.\n",
    "\n",
    "Note: if you decide to apply this approach to our task as part of an original system, recall that `vsm.word_relatedness_evaluation` returns `-d` where `d` is the value computed by `distfunc`, since it assumes that `distfunc` is a distance value of some kind rather than a relatedness/similarity value. Since most regression models will return positive scores for positive associations, you will probably want to undo this by having your `distfunc` return the negative of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "def knn_represent(word1, word2, vsm_df):\n",
    "    # Use `vsm_df` to get vectors for `word1` and `word2`\n",
    "    # and concatenate them into a single vector:\n",
    "    ##### YOUR CODE HERE\n",
    "    return np.concatenate([vsm_df.loc[word1], vsm_df.loc[word2]])\n",
    "\n",
    "\n",
    "def knn_feature_matrix(vsm_df, rel_df):\n",
    "    # Complete `knn_represent` and use it to create a feature\n",
    "    # matrix `np.array`:\n",
    "    ##### YOUR CODE HERE\n",
    "    return np.array(\n",
    "        [knn_represent(row.word1, row.word2, vsm_df) for _, row in rel_df.iterrows()]\n",
    "    )\n",
    "\n",
    "def run_knn_score_model(vsm_df, dev_df, test_size=0.20):\n",
    "\n",
    "    # Complete `knn_feature_matrix` for this step.\n",
    "    ##### YOUR CODE HERE\n",
    "    x = knn_feature_matrix(vsm_df, dev_df)\n",
    "\n",
    "    # Get the values of the 'score' column in `dev_df`\n",
    "    # and store them in a list or array `y`.\n",
    "    ##### YOUR CODE HERE\n",
    "    y = dev_df.score.values\n",
    "\n",
    "    # Use `train_test_split` to split (X, y) into train and\n",
    "    # test protions, with `test_size` as the test size.\n",
    "    ##### YOUR CODE HERE\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "\n",
    "    # Instantiate a `KNeighborsRegressor` with default arguments:\n",
    "    ##### YOUR CODE HERE\n",
    "    knn_regressor = KNeighborsRegressor()\n",
    "\n",
    "    # Fit the model on the training data:\n",
    "    ##### YOUR CODE HERE\n",
    "    knn_regressor.fit(x_train, y_train)\n",
    "\n",
    "    # Return the value of `score` for your model on the test split\n",
    "    # you created above:\n",
    "    ##### YOUR CODE HERE\n",
    "    return knn_regressor.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn_feature_matrix(func):\n",
    "    rel_df = pd.DataFrame([\n",
    "        {'word1': 'w1', 'word2': 'w2', 'score': 0.1},\n",
    "        {'word1': 'w1', 'word2': 'w3', 'score': 0.2}])\n",
    "    vsm_df = pd.DataFrame([\n",
    "        [1, 2, 3.],\n",
    "        [4, 5, 6.],\n",
    "        [7, 8, 9.]], index=['w1', 'w2', 'w3'])\n",
    "    expected = np.array([\n",
    "        [1, 2, 3, 4, 5, 6.],\n",
    "        [1, 2, 3, 7, 8, 9.]])\n",
    "    result = func(vsm_df, rel_df)\n",
    "    assert np.array_equal(result, expected), \\\n",
    "        \"Your `knn_feature_matrix` returns: {}\\nWe expect: {}\".format(\n",
    "        result, expected)\n",
    "\n",
    "def test_knn_represent(func):\n",
    "    vsm_df = pd.DataFrame([\n",
    "        [1, 2, 3.],\n",
    "        [4, 5, 6.],\n",
    "        [7, 8, 9.]], index=['w1', 'w2', 'w3'])\n",
    "    result = func('w1', 'w3', vsm_df)\n",
    "    expected = np.array([1, 2, 3, 7, 8, 9.])\n",
    "    assert np.array_equal(result, expected), \\\n",
    "        \"Your `knn_represent` returns: {}\\nWe expect: {}\".format(\n",
    "        result, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_knn_represent(knn_represent)\n",
    "    test_knn_feature_matrix(knn_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your original system [3 points]\n",
    "\n",
    "This question asks you to design your own model. You can of course include steps made above (ideally, the above questions informed your system design!), but your model should not be literally identical to any of the above models. Other ideas: retrofitting, autoencoders, GloVe, subword modeling, ... \n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. Your system must work with `vsm.word_relatedness_evaluation`. You are free to specify the VSM and the value of `distfunc`.\n",
    "\n",
    "1. Your code must be self-contained, so that we can work with your model directly in your homework submission notebook. If your model depends on external data or other resources, please submit a ZIP archive containing these resources along with your submission.\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies. We also ask that you report the best score your system got during development, just to help us understand how systems performed overall.\n",
    "\n",
    "<font color='red'>Please review the descriptions in the following comment and follow the instructions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_vsm = vsm.create_subword_pooling_vsm(\n",
    "    full_task_vocab, bert_tokenizer, bert_model, layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = utils.glove2dict(\n",
    "    os.path.join('data', 'glove.6B', 'glove.6B.300d.txt'))\n",
    "\n",
    "X_glove = pd.DataFrame(glove_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3687280256328059,\n",
       " 0.5484652960364981,\n",
       " 0.5967776957411588,\n",
       " 0.6630058846678645)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "#   3) The score achieved by your system in place of MY_NUMBER.\n",
    "#        With no other changes to that line.\n",
    "#        You should report your score as a decimal value <=1.0\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# NOTE: MODULES, CODE AND DATASETS REQUIRED FOR YOUR ORIGINAL SYSTEM\n",
    "# SHOULD BE ADDED BELOW THE 'IS_GRADESCOPE_ENV' CHECK CONDITION. DOING\n",
    "# SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "# My peak score was: 0.663\n",
    "# Glove + LSA is the best\n",
    "if \"IS_GRADESCOPE_ENV\" not in os.environ:\n",
    "    pass\n",
    "\n",
    "train_df, test_df = train_test_split(dev_df, test_size=0.2)\n",
    "x_train = knn_feature_matrix(bert_vsm, train_df)\n",
    "y_train = train_df.score.values\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "knn_regressor.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "def bert_knn_predictor(u, v):\n",
    "    return -knn_regressor.predict(\n",
    "        np.expand_dims(np.concatenate((u.values, v.values)), axis=0)\n",
    "    )[0]\n",
    "\n",
    "\n",
    "_pred, score = vsm.word_relatedness_evaluation(test_df, bert_vsm, distfunc=bert_knn_predictor)\n",
    "_pred_train, score_train = vsm.word_relatedness_evaluation(dev_df, bert_vsm, distfunc=bert_knn_predictor)\n",
    "\n",
    "glove_lsa = vsm.lsa(X_glove, k=240)\n",
    "_pred, score_glove_lsa = vsm.word_relatedness_evaluation(dev_df, glove_lsa, distfunc=vsm.cosine)\n",
    "\n",
    "score, score_train, score_train2, score_glove_lsa\n",
    "\n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert Cosine\n",
    "\n",
    "You can see layer 1 is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5172559913305164\n",
      "1 0.5967776957411588\n",
      "2 0.49401314892842324\n",
      "3 0.44889050709966105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m13\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     bert_vsm \u001b[39m=\u001b[39m vsm\u001b[39m.\u001b[39;49mcreate_subword_pooling_vsm(\n\u001b[1;32m      3\u001b[0m         full_task_vocab, bert_tokenizer, bert_model, layer\u001b[39m=\u001b[39;49mlayer)\n\u001b[1;32m      4\u001b[0m     _pred_train, score_train \u001b[39m=\u001b[39m vsm\u001b[39m.\u001b[39mword_relatedness_evaluation(dev_df, bert_vsm, distfunc\u001b[39m=\u001b[39mvsm\u001b[39m.\u001b[39mcosine)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(layer, score_train)\n",
      "File \u001b[0;32m~/cs224u/vsm.py:439\u001b[0m, in \u001b[0;36mcreate_subword_pooling_vsm\u001b[0;34m(vocab, tokenizer, model, layer, pool_func)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_subword_pooling_vsm\u001b[39m(vocab, tokenizer, model, layer\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pool_func\u001b[39m=\u001b[39mmean_pooling):\n\u001b[1;32m    438\u001b[0m     vocab_ids \u001b[39m=\u001b[39m [hf_encode(w, tokenizer) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m vocab]\n\u001b[0;32m--> 439\u001b[0m     vocab_hiddens \u001b[39m=\u001b[39m [hf_represent(w, model, layer\u001b[39m=\u001b[39mlayer) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m vocab_ids]\n\u001b[1;32m    440\u001b[0m     pooled \u001b[39m=\u001b[39m [pool_func(h) \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m vocab_hiddens]\n\u001b[1;32m    441\u001b[0m     pooled \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pooled]\n",
      "File \u001b[0;32m~/cs224u/vsm.py:439\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_subword_pooling_vsm\u001b[39m(vocab, tokenizer, model, layer\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pool_func\u001b[39m=\u001b[39mmean_pooling):\n\u001b[1;32m    438\u001b[0m     vocab_ids \u001b[39m=\u001b[39m [hf_encode(w, tokenizer) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m vocab]\n\u001b[0;32m--> 439\u001b[0m     vocab_hiddens \u001b[39m=\u001b[39m [hf_represent(w, model, layer\u001b[39m=\u001b[39;49mlayer) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m vocab_ids]\n\u001b[1;32m    440\u001b[0m     pooled \u001b[39m=\u001b[39m [pool_func(h) \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m vocab_hiddens]\n\u001b[1;32m    441\u001b[0m     pooled \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pooled]\n",
      "File \u001b[0;32m~/cs224u/vsm.py:302\u001b[0m, in \u001b[0;36mhf_represent\u001b[0;34m(batch_ids, model, layer)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mEncode a batch of sequences of ids using a Hugging Face\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39mTransformer-based model `model`. The model's `forward` method is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \n\u001b[1;32m    300\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 302\u001b[0m     reps \u001b[39m=\u001b[39m model(batch_ids, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m reps\u001b[39m.\u001b[39mhidden_states[layer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    605\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    613\u001b[0m         hidden_states,\n\u001b[1;32m    614\u001b[0m         attention_mask,\n\u001b[1;32m    615\u001b[0m         layer_head_mask,\n\u001b[1;32m    616\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    617\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    618\u001b[0m         past_key_value,\n\u001b[1;32m    619\u001b[0m         output_attentions,\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[0;32m--> 436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:387\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    386\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 387\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    388\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[1;32m    389\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39m, p, training)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/cs224u/lib/python3.10/site-packages/torch/_VF.py:26\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(name)\n\u001b[1;32m     24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for layer in range(13):\n",
    "    bert_vsm = vsm.create_subword_pooling_vsm(\n",
    "        full_task_vocab, bert_tokenizer, bert_model, layer=layer)\n",
    "    _pred_train, score_train = vsm.word_relatedness_evaluation(dev_df, bert_vsm, distfunc=vsm.cosine)\n",
    "    print(layer, score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Retrofitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converged at iteration 8; change was 0.0064 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4466897205571942, 0.5967776957411588)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from retrofitting import Retrofitter\n",
    "\n",
    "def get_wordnet_edges():\n",
    "    edges = defaultdict(set)\n",
    "    for ss in wn.all_synsets():\n",
    "        lem_names = {lem.name() for lem in ss.lemmas()}\n",
    "        for lem in lem_names:\n",
    "            edges[lem] |= lem_names\n",
    "    return edges\n",
    "\n",
    "def convert_edges_to_indices(edges, Q):\n",
    "    lookup = dict(zip(Q.index, range(Q.shape[0])))\n",
    "    index_edges = defaultdict(set)\n",
    "    for start, finish_nodes in edges.items():\n",
    "        s = lookup.get(start)\n",
    "        if s:\n",
    "            f = {lookup[n] for n in finish_nodes if n in lookup}\n",
    "            if f:\n",
    "                index_edges[s] = f\n",
    "    return index_edges\n",
    "\n",
    "wn_edges = get_wordnet_edges()\n",
    "wn_index_edges = convert_edges_to_indices(wn_edges, bert_vsm)\n",
    "wn_retro = Retrofitter(verbose=True)\n",
    "bert_retro = wn_retro.fit(bert_vsm, wn_index_edges)\n",
    "_pred, score_retro = vsm.word_relatedness_evaluation(dev_df, bert_retro, distfunc=vsm.cosine)\n",
    "_pred, score_bert = vsm.word_relatedness_evaluation(dev_df, bert_vsm, distfunc=vsm.cosine)\n",
    "score_retro, score_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000128427132526"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_lsa = vsm.lsa(bert_vsm, k=300)\n",
    "_pred, score = vsm.word_relatedness_evaluation(dev_df, bert_lsa, distfunc=vsm.cosine)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6611667449633439"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_dict = utils.glove2dict(\n",
    "    os.path.join('data', 'glove.6B', 'glove.6B.300d.txt'))\n",
    "\n",
    "X_glove = pd.DataFrame(glove_dict).T\n",
    "_pred, score = vsm.word_relatedness_evaluation(dev_df, X_glove, distfunc=vsm.cosine)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6630058846678645"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_lsa = vsm.lsa(X_glove, k=240)\n",
    "_pred, score = vsm.word_relatedness_evaluation(dev_df, glove_lsa, distfunc=vsm.cosine)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove Retrofitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_retro  = pd.read_csv(\n",
    "        os.path.join('data', \"glove6B300d-retrofit-wn.csv.gz\"), index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6602365694179283"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pred, score = vsm.word_relatedness_evaluation(dev_df, X_retro)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off [1 point]\n",
    "\n",
    "For the bake-off, you simply need to evaluate your original system on the file \n",
    "\n",
    "`wordrelatedness/cs224u-wordrelatedness-test-unlabeled.csv`\n",
    "\n",
    "This contains only word pairs (no scores), so `vsm.word_relatedness_evaluation` will simply make predictions without doing any scoring. Use that function to make predictions with your original system, store the resulting `pred_df` to a file, and then upload the file as your bake-off submission.\n",
    "\n",
    "The following function should be used to conduct this evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_submission(\n",
    "        vsm_df,\n",
    "        distfunc,\n",
    "        output_filename=\"cs224u-wordrelatedness-bakeoff-entry.csv\"):\n",
    "\n",
    "    test_df = pd.read_csv(\n",
    "        os.path.join(DATA_HOME, \"cs224u-wordrelatedness-test-unlabeled.csv\"))\n",
    "\n",
    "    pred_df, _ = vsm.word_relatedness_evaluation(test_df, vsm_df, distfunc=distfunc)\n",
    "\n",
    "    pred_df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if `count_df` were the VSM for my system, and I wanted my distance function to be `vsm.euclidean`, I would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This check ensure that the following code only runs on the local environment.\n",
    "# The following call will not be run on the autograder environment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    pass\n",
    "    create_bakeoff_submission(count_df, vsm.euclidean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a file `cs224u-wordrelatedness-bakeoff-entry.csv` in the current directory. That file should be uploaded as-is. Please do not change its name.\n",
    "\n",
    "Only one upload per team is permitted, and you should do no tuning of your system based on what you see in `pred_df` â€“ you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n",
    "\n",
    "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "\n",
    "Review and follow the [Homework and bake-off code: Formatting guide](hw_formatting_guide.ipynb).\n",
    "Please do not change the filename as described below.\n",
    "\n",
    "Submit the following files to Gradescope:\n",
    "\n",
    "- `hw_wordrelatedness.ipynb` (this notebook)\n",
    "- `cs224u-wordrelatedness-bakeoff-entry.csv` (bake-off output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "81ef301a63437b26d6f879bc64646dce7fed7674109198cc71f09ca02787000d"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
